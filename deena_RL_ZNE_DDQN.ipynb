{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3MieStKRLA6d",
        "outputId": "bfb7a5e4-1817-412b-ebb5-587d089a6ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping qiskit as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping qiskit-terra as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping qiskit-aer as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping qiskit-ibm-runtime as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torch 2.9.0+cu126\n",
            "Uninstalling torch-2.9.0+cu126:\n",
            "  Successfully uninstalled torch-2.9.0+cu126\n",
            "Found existing installation: torchvision 0.24.0+cu126\n",
            "Uninstalling torchvision-0.24.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.24.0+cu126\n",
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Collecting qiskit==2.1.1\n",
            "  Downloading qiskit-2.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit==2.1.1)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit==2.1.1) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit==2.1.1) (1.16.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit==2.1.1) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit==2.1.1)\n",
            "  Downloading stevedore-5.6.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit==2.1.1) (4.15.0)\n",
            "Downloading qiskit-2.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m156.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.6.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m221.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stevedore, rustworkx, qiskit\n",
            "Successfully installed qiskit-2.1.1 rustworkx-0.17.1 stevedore-5.6.0\n",
            "Collecting qiskit-aer==0.17.1\n",
            "  Downloading qiskit_aer-0.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: qiskit>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer==0.17.1) (2.1.1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer==0.17.1) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer==0.17.1) (1.16.3)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer==0.17.1) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer==0.17.1) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->qiskit-aer==0.17.1) (1.17.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.1.0->qiskit-aer==0.17.1) (0.17.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.1.0->qiskit-aer==0.17.1) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.1.0->qiskit-aer==0.17.1) (5.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.1.0->qiskit-aer==0.17.1) (4.15.0)\n",
            "Downloading qiskit_aer-0.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit-aer\n",
            "Successfully installed qiskit-aer-0.17.1\n",
            "Collecting qiskit-ibm-runtime==0.40.1\n",
            "  Downloading qiskit_ibm_runtime-0.40.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime==0.40.1) (2.32.4)\n",
            "Collecting requests-ntlm>=1.1.0 (from qiskit-ibm-runtime==0.40.1)\n",
            "  Downloading requests_ntlm-1.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime==0.40.1) (2.0.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime==0.40.1) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime==0.40.1) (2.9.0.post0)\n",
            "Collecting ibm-platform-services>=0.22.6 (from qiskit-ibm-runtime==0.40.1)\n",
            "  Downloading ibm_platform_services-0.71.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime==0.40.1) (2.12.3)\n",
            "Requirement already satisfied: qiskit>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime==0.40.1) (2.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-runtime==0.40.1) (25.0)\n",
            "Collecting ibm_cloud_sdk_core<4.0.0,>=3.24.2 (from ibm-platform-services>=0.22.6->qiskit-ibm-runtime==0.40.1)\n",
            "  Downloading ibm_cloud_sdk_core-3.24.2-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime==0.40.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime==0.40.1) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime==0.40.1) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime==0.40.1) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->qiskit-ibm-runtime==0.40.1) (1.17.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.4.1->qiskit-ibm-runtime==0.40.1) (0.17.1)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.4.1->qiskit-ibm-runtime==0.40.1) (1.16.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.4.1->qiskit-ibm-runtime==0.40.1) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.4.1->qiskit-ibm-runtime==0.40.1) (5.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19->qiskit-ibm-runtime==0.40.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19->qiskit-ibm-runtime==0.40.1) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19->qiskit-ibm-runtime==0.40.1) (2025.11.12)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.12/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-runtime==0.40.1) (43.0.3)\n",
            "Collecting pyspnego>=0.4.0 (from requests-ntlm>=1.1.0->qiskit-ibm-runtime==0.40.1)\n",
            "  Downloading pyspnego-0.12.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime==0.40.1) (2.0.0)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from ibm_cloud_sdk_core<4.0.0,>=3.24.2->ibm-platform-services>=0.22.6->qiskit-ibm-runtime==0.40.1) (2.10.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime==0.40.1) (2.23)\n",
            "Downloading qiskit_ibm_runtime-0.40.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ibm_platform_services-0.71.0-py3-none-any.whl (377 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.4/377.4 kB\u001b[0m \u001b[31m414.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_ntlm-1.3.0-py3-none-any.whl (6.6 kB)\n",
            "Downloading ibm_cloud_sdk_core-3.24.2-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m362.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyspnego-0.12.0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m368.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ibm_cloud_sdk_core, pyspnego, ibm-platform-services, requests-ntlm, qiskit-ibm-runtime\n",
            "Successfully installed ibm-platform-services-0.71.0 ibm_cloud_sdk_core-3.24.2 pyspnego-0.12.0 qiskit-ibm-runtime-0.40.1 requests-ntlm-1.3.0\n",
            "Collecting qiskit-addon-utils==0.1.1\n",
            "  Downloading qiskit_addon_utils-0.1.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from qiskit-addon-utils==0.1.1) (2.0.2)\n",
            "Requirement already satisfied: qiskit<3,>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit-addon-utils==0.1.1) (2.1.1)\n",
            "Requirement already satisfied: rustworkx>=0.15 in /usr/local/lib/python3.12/dist-packages (from qiskit-addon-utils==0.1.1) (0.17.1)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit<3,>=1.2->qiskit-addon-utils==0.1.1) (1.16.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit<3,>=1.2->qiskit-addon-utils==0.1.1) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit<3,>=1.2->qiskit-addon-utils==0.1.1) (5.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit<3,>=1.2->qiskit-addon-utils==0.1.1) (4.15.0)\n",
            "Downloading qiskit_addon_utils-0.1.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: qiskit-addon-utils\n",
            "Successfully installed qiskit-addon-utils-0.1.1\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Collecting torch==2.4.1\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.4.1%2Bcpu-cp312-cp312-linux_x86_64.whl (194.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 MB\u001b[0m \u001b[31m287.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (75.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.1) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.8.5 requires torchvision>=0.11, which is not installed.\n",
            "timm 1.0.22 requires torchvision, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.4.1+cpu\n",
            "Collecting gymnasium==0.29.1\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.13.1\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m333.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.9.2\n",
            "  Downloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (0.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.17.0)\n",
            "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m314.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m202.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m190.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gymnasium, matplotlib\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.2\n",
            "    Uninstalling gymnasium-1.2.2:\n",
            "      Successfully uninstalled gymnasium-1.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.8.5 requires torchvision>=0.11, which is not installed.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.29.1 matplotlib-3.9.2 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "3cefc52dfb1e44718dac194673b7bd09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mitiq\n",
            "  Downloading mitiq-0.48.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from mitiq) (1.26.4)\n",
            "Requirement already satisfied: scipy<=1.16.2,>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from mitiq) (1.13.1)\n",
            "Collecting cirq-core<1.7.0,>=1.6.0 (from mitiq)\n",
            "  Downloading cirq_core-1.6.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from mitiq) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from mitiq) (3.9.2)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.12/dist-packages (from cirq-core<1.7.0,>=1.6.0->mitiq) (25.4.0)\n",
            "Collecting duet>=0.2.8 (from cirq-core<1.7.0,>=1.6.0->mitiq)\n",
            "  Downloading duet-0.2.9-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: networkx~=3.4 in /usr/local/lib/python3.12/dist-packages (from cirq-core<1.7.0,>=1.6.0->mitiq) (3.6)\n",
            "Requirement already satisfied: pandas~=2.1 in /usr/local/lib/python3.12/dist-packages (from cirq-core<1.7.0,>=1.6.0->mitiq) (2.2.2)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.12/dist-packages (from cirq-core<1.7.0,>=1.6.0->mitiq) (2.4.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from cirq-core<1.7.0,>=1.6.0->mitiq) (1.14.0)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from cirq-core<1.7.0,>=1.6.0->mitiq) (4.15.0)\n",
            "Requirement already satisfied: tqdm>=4.12 in /usr/local/lib/python3.12/dist-packages (from cirq-core<1.7.0,>=1.6.0->mitiq) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mitiq) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mitiq) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mitiq) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mitiq) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mitiq) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mitiq) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mitiq) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mitiq) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas~=2.1->cirq-core<1.7.0,>=1.6.0->mitiq) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas~=2.1->cirq-core<1.7.0,>=1.6.0->mitiq) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8->mitiq) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->cirq-core<1.7.0,>=1.6.0->mitiq) (1.3.0)\n",
            "Downloading mitiq-0.48.1-py3-none-any.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.8/336.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_core-1.6.1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duet-0.2.9-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: duet, cirq-core, mitiq\n",
            "Successfully installed cirq-core-1.6.1 duet-0.2.9 mitiq-0.48.1\n",
            "Installation complete.\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y qiskit qiskit-terra qiskit-aer qiskit-ibm-runtime torch torchvision torchaudio\n",
        "\n",
        "!pip install 'qiskit==2.1.1' --no-cache-dir\n",
        "!pip install 'qiskit-aer==0.17.1' --no-cache-dir\n",
        "!pip install 'qiskit-ibm-runtime==0.40.1' --no-cache-dir\n",
        "!pip install 'qiskit-addon-utils==0.1.1' --no-cache-dir\n",
        "\n",
        "!pip install 'torch==2.4.1' --index-url https://download.pytorch.org/whl/cpu --no-cache-dir\n",
        "!pip install 'gymnasium==0.29.1' 'numpy==1.26.4' 'scipy==1.13.1' 'matplotlib==3.9.2' --no-cache-dir\n",
        "\n",
        "!pip install --upgrade mitiq --no-cache-dir\n",
        "\n",
        "print(\"Installation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from qiskit import QuantumCircuit, transpile\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit.circuit.library import PauliEvolutionGate\n",
        "from qiskit.synthesis import LieTrotter\n",
        "from qiskit.transpiler import CouplingMap\n",
        "from qiskit.exceptions import QiskitError\n",
        "\n",
        "from qiskit_addon_utils.problem_generators import generate_xyz_hamiltonian\n",
        "\n",
        "# Qiskit Runtime & Aer\n",
        "from qiskit_aer import AerSimulator\n",
        "from qiskit_aer.noise import NoiseModel, depolarizing_error\n",
        "from qiskit_ibm_runtime.debug_tools import Neat\n",
        "\n",
        "# Mitiq\n",
        "import mitiq\n",
        "from mitiq.zne.scaling import fold_gates_at_random\n",
        "from mitiq.zne.inference import RichardsonFactory\n",
        "\n",
        "# PyTorch & RL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "print(\"All imports successful.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya4E7Ahwglpz",
        "outputId": "e6ddd9c0-44a5-4576-cf74-fae2aad1ada5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_LEVEL = 0.02\n",
        "SHOTS = 4096\n",
        "\n",
        "# Define Noise Model on HARDWARE Basis Gates\n",
        "nm = NoiseModel()\n",
        "err1 = depolarizing_error(NOISE_LEVEL, 1)\n",
        "err2 = depolarizing_error(NOISE_LEVEL * 2, 2)\n",
        "\n",
        "nm.add_all_qubit_quantum_error(err1, ['sx', 'x', 'rz', 'id'])\n",
        "nm.add_all_qubit_quantum_error(err2, ['cx'])\n",
        "\n",
        "# Backends\n",
        "backend_noisy = AerSimulator(noise_model=nm)\n",
        "backend_ideal = AerSimulator()\n",
        "\n",
        "# Executors\n",
        "def executor_ideal(circuit, observable):\n",
        "    from qiskit_aer.primitives import Estimator\n",
        "    est = Estimator()\n",
        "    job = est.run(circuits=[circuit], observables=[observable], shots=SHOTS)\n",
        "    return job.result().values[0]\n",
        "\n",
        "def executor_noisy(circuit, observable):\n",
        "    from qiskit_aer.primitives import Estimator\n",
        "    est = Estimator(backend_options={\"noise_model\": nm})\n",
        "    job = est.run(circuits=[circuit], observables=[observable], shots=SHOTS)\n",
        "    return job.result().values[0]\n",
        "\n",
        "# Extrapolation Functions\n",
        "def linear_extrapolate(scale_factors, exp_vals):\n",
        "    if len(scale_factors) < 2: return exp_vals[0]\n",
        "    z = np.polyfit(scale_factors, exp_vals, 1)\n",
        "    return z[1]\n",
        "\n",
        "def polynomial_extrapolate(scale_factors, exp_vals, degree=2):\n",
        "    if len(scale_factors) < degree + 1: return exp_vals[0]\n",
        "    z = np.polyfit(scale_factors, exp_vals, degree)\n",
        "    return z[degree]\n",
        "\n",
        "def exponential_extrapolate(scale_factors, exp_vals):\n",
        "    try:\n",
        "        valid = [(x, y) for x, y in zip(scale_factors, exp_vals) if y > 1e-5]\n",
        "        if len(valid) < 2: return exp_vals[0]\n",
        "        x, y = zip(*valid)\n",
        "        coeffs = np.polyfit(x, np.log(y), 1)\n",
        "        return np.exp(coeffs[1])\n",
        "    except:\n",
        "        return exp_vals[0]\n",
        "\n",
        "def richardson_extrapolate(scale_factors, exp_vals):\n",
        "    try:\n",
        "        return RichardsonFactory(scale_factors).extrapolate(scale_factors, exp_vals)\n",
        "    except:\n",
        "        return exp_vals[0]\n",
        "\n",
        "print(\"Backends and executors ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZWoSOxxYYBt",
        "outputId": "6d7bb7a0-6b5f-4e56-f7f9-78d0ed58fd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backends and executors ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HamiltonianGenerator:\n",
        "    def __init__(self, seed=42):\n",
        "        self.rng = np.random.RandomState(seed)\n",
        "\n",
        "    def generate_base_circuit(self, num_qubits=4, trotter_steps=2):\n",
        "        layout = [(i, i+1) for i in range(num_qubits-1)]\n",
        "        cmap = CouplingMap(layout)\n",
        "\n",
        "        ham = generate_xyz_hamiltonian(\n",
        "            cmap,\n",
        "            coupling_constants=(\n",
        "                self.rng.uniform(0.1, 0.5), self.rng.uniform(0.1, 0.5), self.rng.uniform(0.1, 0.5)\n",
        "            ),\n",
        "            ext_magnetic_field=(\n",
        "                self.rng.uniform(0.05, 0.2), self.rng.uniform(0.05, 0.2), self.rng.uniform(0.05, 0.2)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        evo_gate = PauliEvolutionGate(\n",
        "            ham,\n",
        "            time=self.rng.uniform(0.2, 1.0),\n",
        "            synthesis=LieTrotter(reps=trotter_steps)\n",
        "        )\n",
        "\n",
        "        circuit = QuantumCircuit(num_qubits)\n",
        "        circuit.append(evo_gate, range(num_qubits))\n",
        "        return circuit.decompose().decompose()\n",
        "\n",
        "gen = HamiltonianGenerator(seed=42)\n",
        "print(\"Generator ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzGkH8MiYa-i",
        "outputId": "c71a4a0d-c878-4dc9-f2da-ce4684321aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ZNEEnvironment(gym.Env):\n",
        "    def __init__(self, generator, backend):\n",
        "        super().__init__()\n",
        "        self.generator = generator\n",
        "\n",
        "        # Initialize NEAT\n",
        "        self.neat = Neat(backend)\n",
        "        self.target_basis = ['cx', 'sx', 'rz', 'x', 'id']\n",
        "\n",
        "        # ... (options initialization remains the same) ...\n",
        "        self.noisefactor_options = [\n",
        "            [1.0, 1.1, 1.2], [1.0, 1.2, 1.3], [1.0, 1.3, 1.5], [1.0, 1.4, 1.6],\n",
        "            [1.0, 1.5, 1.8], [1.0, 1.7, 1.9], [1.0, 2.0, 2.5], [1.0, 2.2, 2.7],\n",
        "            [1.0, 2.5, 2.9], [1, 2, 3], [1, 2, 4], [1, 3, 5],\n",
        "            [1.0, 3.0, 3.5], [1.0, 3.2, 3.8], [1.0, 3.5, 3.9], [1.0, 4.0, 5.0],\n",
        "            [1.0, 4.5, 5.0], [1, 3, 5, 7], [1, 5, 7], [1.0, 6.0, 7.0],\n",
        "            [1, 1.5, 2.5, 4], [1, 2, 3, 5], [1, 3, 5, 7], [1, 1.2, 2.5, 5],\n",
        "            [1, 1.5, 3, 7], [1.0, 1.8, 2.5], [1.0, 2.0, 3.5], [1.0, 3.0, 5.0],\n",
        "            [1.0, 2.5, 4.0], [1.0, 3.5, 6.0]\n",
        "        ]\n",
        "        self.extrapolators = ['linear', 'polynomial', 'exponential', 'richardson']\n",
        "\n",
        "        n_actions = len(self.noisefactor_options) * len(self.extrapolators)\n",
        "        self.action_space = spaces.Discrete(n_actions)\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(6,), dtype=np.float32)\n",
        "\n",
        "        self.num_qubits = 4\n",
        "        self.trotter_steps = 2\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        if seed is not None:\n",
        "            self.generator.rng = np.random.RandomState(seed)\n",
        "\n",
        "        nq = self.num_qubits\n",
        "\n",
        "        # 1. Generate & Transpile Circuit (H-gate fix)\n",
        "        raw_circuit = self.generator.generate_base_circuit(nq, self.trotter_steps)\n",
        "        self.base_u = transpile(raw_circuit, basis_gates=self.target_basis, optimization_level=1)\n",
        "\n",
        "        # 2. Define Observable\n",
        "        raw_obs = SparsePauliOp(['I'*i + 'Z' + 'I'*(nq-1-i) for i in range(nq)], coeffs=[1.0/nq]*nq)\n",
        "\n",
        "        # 3. Cliffordization using NEAT\n",
        "        pubs = [(self.base_u, [raw_obs])] # List wrap fix\n",
        "        clifford_pubs = self.neat.to_clifford(pubs)\n",
        "\n",
        "        self.circuit = clifford_pubs[0].circuit\n",
        "\n",
        "        # --- FINAL FIX: TYPE CASTING & RECONSTRUCTION ---\n",
        "        neat_obs_container = clifford_pubs[0].observables[0]\n",
        "\n",
        "        if isinstance(neat_obs_container, dict):\n",
        "            # the structure is {'PauliString': coefficient}\n",
        "            # must explicitly cast coefficients to complex to satisfy Qiskit's low-level constructor.\n",
        "\n",
        "            try:\n",
        "                # 1. Extract and cast to list of (Pauli, complex coeff) tuples\n",
        "                pauli_list_tuples = [\n",
        "                    (pauli_str, complex(coeff))\n",
        "                    for pauli_str, coeff in neat_obs_container.items()\n",
        "                ]\n",
        "                # 2. Use the stable from_list constructor\n",
        "                self.observable = SparsePauliOp.from_list(pauli_list_tuples)\n",
        "            except Exception as e:\n",
        "                # If extraction fails (e.g., nested keys are back), raise an informative QiskitError.\n",
        "                raise QiskitError(f\"Failed to reconstruct Observable due to incompatible data format or casting error. Keys: {list(neat_obs_container.keys())}. Underlying Error: {e}\")\n",
        "\n",
        "        else:\n",
        "            # Fallback: Object is already a SparsePauliOp instance\n",
        "            self.observable = SparsePauliOp.from_list(neat_obs_container.to_list())\n",
        "\n",
        "        # 4. Features & Ideal Value\n",
        "        ops = self.circuit.count_ops()\n",
        "        self.features = {\n",
        "            'qubits': nq,\n",
        "            'cx_gates': ops.get('cx', 0) + ops.get('cz', 0),\n",
        "            'single_gates': sum(ops.get(g, 0) for g in ['sx', 'x', 'rz', 'id']),\n",
        "            'depth': self.circuit.depth(),\n",
        "            'total_gates': sum(ops.values()),\n",
        "            'ham_terms': 3*nq + 3*(nq-1)\n",
        "        }\n",
        "\n",
        "        self.ideal = executor_ideal(self.circuit, self.observable)\n",
        "\n",
        "        state = np.array(list(self.features.values()), dtype=np.float32)\n",
        "        return state, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        template_idx = action // len(self.extrapolators)\n",
        "        extrap_idx = action % len(self.extrapolators)\n",
        "        scales = self.noisefactor_options[template_idx]\n",
        "        extrap_name = self.extrapolators[extrap_idx]\n",
        "\n",
        "        # Fold the Clifford circuit\n",
        "        folded_circs = [fold_gates_at_random(self.circuit, s) for s in scales]\n",
        "        noisy_vals = [executor_noisy(fc, self.observable) for fc in folded_circs]\n",
        "\n",
        "        # Extrapolate\n",
        "        if extrap_name == 'linear': mitigated = linear_extrapolate(scales, noisy_vals)\n",
        "        elif extrap_name == 'polynomial': mitigated = polynomial_extrapolate(scales, noisy_vals)\n",
        "        elif extrap_name == 'exponential': mitigated = exponential_extrapolate(scales, noisy_vals)\n",
        "        else: mitigated = richardson_extrapolate(scales, noisy_vals)\n",
        "\n",
        "        error = abs(mitigated - self.ideal)\n",
        "        reward = -error\n",
        "\n",
        "        state = np.array(list(self.features.values()), dtype=np.float32)\n",
        "        return state, reward, True, False, {'error': error}\n",
        "\n",
        "env = ZNEEnvironment(gen, backend_noisy)\n",
        "print(f\"Env initialized. Actions: {env.action_space.n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx3ChBVghUGL",
        "outputId": "1545711f-bda4-4e11-bdfb-69b53153677a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Env initialized. Actions: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DuelingDQN(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            nn.Linear(state_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.value = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "        self.advantage = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 2, action_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature(x)\n",
        "        value = self.value(features)\n",
        "        advantage = self.advantage(features)\n",
        "        return value + (advantage - advantage.mean(dim=1, keepdim=True))\n",
        "\n",
        "class PrioritizedReplayBuffer:\n",
        "    def __init__(self, capacity, alpha=0.6, beta=0.4, beta_increment=0.001):\n",
        "        self.capacity = capacity\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.beta_increment = beta_increment\n",
        "        self.buffer = []\n",
        "        self.priorities = np.zeros(capacity, dtype=np.float32)\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, transition, td_error):\n",
        "        priority = (abs(td_error) + 1e-5) ** self.alpha\n",
        "        if len(self.buffer) < self.capacity:\n",
        "            self.buffer.append(transition)\n",
        "        else:\n",
        "            self.buffer[self.position] = transition\n",
        "        self.priorities[self.position] = priority\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        buffer_size = len(self.buffer)\n",
        "        priorities = self.priorities[:buffer_size]\n",
        "        probs = priorities / priorities.sum()\n",
        "        indices = np.random.choice(buffer_size, batch_size, p=probs)\n",
        "        weights = (buffer_size * probs[indices]) ** (-self.beta)\n",
        "        weights /= weights.max()\n",
        "        self.beta = min(1.0, self.beta + self.beta_increment)\n",
        "        batch = [self.buffer[i] for i in indices]\n",
        "        return batch, indices, torch.FloatTensor(weights)\n",
        "\n",
        "    def update_priorities(self, indices, td_errors):\n",
        "        for idx, td_error in zip(indices, td_errors):\n",
        "            self.priorities[idx] = (abs(td_error) + 1e-5) ** self.alpha\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "class DoubleDQNAgent:\n",
        "    def __init__(self, state_dim, action_dim, lr=1e-4, gamma=0.99, tau=0.005, buffer_size=50000):\n",
        "        self.action_dim = action_dim\n",
        "        self.gamma = gamma\n",
        "        self.tau = tau\n",
        "        self.q_network = DuelingDQN(state_dim, action_dim)\n",
        "        self.target_network = DuelingDQN(state_dim, action_dim)\n",
        "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
        "        self.optimizer = torch.optim.Adam(self.q_network.parameters(), lr=lr)\n",
        "        self.memory = PrioritizedReplayBuffer(buffer_size)\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.05\n",
        "        self.epsilon_decay = 0.9995\n",
        "\n",
        "    def select_action(self, state, training=True):\n",
        "        if training and random.random() < self.epsilon:\n",
        "            return random.randrange(self.action_dim)\n",
        "        with torch.no_grad():\n",
        "            return self.q_network(torch.FloatTensor(state).unsqueeze(0)).argmax().item()\n",
        "\n",
        "    def store_transition(self, state, action, reward, next_state, done):\n",
        "        with torch.no_grad():\n",
        "            current_q = self.q_network(torch.FloatTensor(state).unsqueeze(0))[0, action]\n",
        "            next_q = self.target_network(torch.FloatTensor(next_state).unsqueeze(0)).max().item()\n",
        "            td_error = reward + self.gamma * next_q * (1 - done) - current_q.item()\n",
        "        self.memory.push((state, action, reward, next_state, done), td_error)\n",
        "\n",
        "    def update(self, batch_size=64):\n",
        "        if len(self.memory) < batch_size: return 0.0\n",
        "        batch, indices, weights = self.memory.sample(batch_size)\n",
        "        states = torch.FloatTensor([t[0] for t in batch])\n",
        "        actions = torch.LongTensor([t[1] for t in batch])\n",
        "        rewards = torch.FloatTensor([t[2] for t in batch])\n",
        "        next_states = torch.FloatTensor([t[3] for t in batch])\n",
        "        dones = torch.FloatTensor([t[4] for t in batch])\n",
        "\n",
        "        current_q = self.q_network(states).gather(1, actions.unsqueeze(1))\n",
        "        with torch.no_grad():\n",
        "            next_actions = self.q_network(next_states).argmax(1)\n",
        "            next_q = self.target_network(next_states).gather(1, next_actions.unsqueeze(1)).squeeze()\n",
        "            target_q = rewards + self.gamma * next_q * (1 - dones)\n",
        "\n",
        "        td_errors = (target_q - current_q.squeeze()).detach().numpy()\n",
        "        self.memory.update_priorities(indices, td_errors)\n",
        "        loss = (weights * F.mse_loss(current_q.squeeze(), target_q, reduction='none')).mean()\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.q_network.parameters(), 10.0)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        for target_param, param in zip(self.target_network.parameters(), self.q_network.parameters()):\n",
        "            target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
        "        return loss.item()\n",
        "\n",
        "agent = DoubleDQNAgent(state_dim=6, action_dim=env.action_space.n)\n",
        "print(\"RL Agent initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DqA4r2uZHGJ",
        "outputId": "3656b38d-e466-484e-b3be-a460d38a7a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RL Agent initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_double_dqn(env, agent, episodes=20000, curriculum_stages=4):\n",
        "    \"\"\"\n",
        "    Training loop for Double DQN with PER and curriculum learning.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "    import numpy as np\n",
        "    import time\n",
        "\n",
        "    train_rewards = []\n",
        "    train_errors = []\n",
        "    action_counts = defaultdict(int)\n",
        "\n",
        "    # Define a complexity schedule based on the original notebook's logic\n",
        "    episodes_per_stage = episodes // curriculum_stages\n",
        "    complexity_schedule = [(2, 4), (3, 4), (4, 4), (4, 4)] # (trotter_steps, num_qubits)\n",
        "\n",
        "    print(f\"Training {episodes} episodes across {curriculum_stages} stages...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        stage = min(episode // episodes_per_stage, curriculum_stages - 1)\n",
        "        trotter, nq = complexity_schedule[stage]\n",
        "\n",
        "        # --- Environment Setup ---\n",
        "        env.num_qubits = nq\n",
        "        env.trotter_steps = trotter\n",
        "        state, _ = env.reset()\n",
        "\n",
        "        # --- Agent Action ---\n",
        "        action = agent.select_action(state, training=True)\n",
        "        action_counts[action] += 1\n",
        "\n",
        "        # --- Environment Step (Single step episode) ---\n",
        "        next_state, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # --- Update Agent (FIXED METHOD NAME) ---\n",
        "        agent.store_transition(state, action, reward, next_state, done)\n",
        "        loss = agent.update(batch_size=64)\n",
        "\n",
        "        # --- Logging ---\n",
        "        train_rewards.append(reward)\n",
        "        train_errors.append(info['error'])\n",
        "\n",
        "        if (episode + 1) % 500 == 0:\n",
        "            print(f\"Ep {episode+1:5d} | Stage {stage+1} ({trotter}T,{nq}q) | Reward: {np.mean(train_rewards[-500:]):+.4f} | Error: {np.mean(train_errors[-500:]):.4f} | ε: {agent.epsilon:.3f}\")\n",
        "\n",
        "    print(f\"Complete in {(time.time()-start_time)/60:.1f}m\")\n",
        "    print(\"Action distribution (Top 5):\", dict(sorted(action_counts.items(), key=lambda item: item[1], reverse=True)[:5]))\n",
        "    return train_rewards, train_errors\n",
        "\n",
        "# Usage (run after agent/env init)\n",
        "train_rewards, train_errors = train_double_dqn(env, agent, episodes=20000, curriculum_stages=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL9QGWBprQL-",
        "outputId": "190c96b5-7016-4d9b-bd28-b8904d0fc18b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training 20000 episodes across 4 stages...\n",
            "Ep   500 | Stage 1 (2T,4q) | Reward: -0.0026 | Error: 0.0026 | ε: 0.804\n",
            "Ep  1000 | Stage 1 (2T,4q) | Reward: -0.0023 | Error: 0.0023 | ε: 0.626\n",
            "Ep  1500 | Stage 1 (2T,4q) | Reward: -0.0021 | Error: 0.0021 | ε: 0.487\n",
            "Ep  2000 | Stage 1 (2T,4q) | Reward: -0.0024 | Error: 0.0024 | ε: 0.380\n",
            "Ep  2500 | Stage 1 (2T,4q) | Reward: -0.0030 | Error: 0.0030 | ε: 0.296\n",
            "Ep  3000 | Stage 1 (2T,4q) | Reward: -0.0034 | Error: 0.0034 | ε: 0.230\n",
            "Ep  3500 | Stage 1 (2T,4q) | Reward: -0.0019 | Error: 0.0019 | ε: 0.179\n",
            "Ep  4000 | Stage 1 (2T,4q) | Reward: -0.0018 | Error: 0.0018 | ε: 0.140\n",
            "Ep  4500 | Stage 1 (2T,4q) | Reward: -0.0019 | Error: 0.0019 | ε: 0.109\n",
            "Ep  5000 | Stage 1 (2T,4q) | Reward: -0.0023 | Error: 0.0023 | ε: 0.085\n",
            "Ep  5500 | Stage 2 (3T,4q) | Reward: -0.0013 | Error: 0.0013 | ε: 0.066\n",
            "Ep  6000 | Stage 2 (3T,4q) | Reward: -0.0015 | Error: 0.0015 | ε: 0.051\n",
            "Ep  6500 | Stage 2 (3T,4q) | Reward: -0.0016 | Error: 0.0016 | ε: 0.050\n",
            "Ep  7000 | Stage 2 (3T,4q) | Reward: -0.0015 | Error: 0.0015 | ε: 0.050\n",
            "Ep  7500 | Stage 2 (3T,4q) | Reward: -0.0012 | Error: 0.0012 | ε: 0.050\n",
            "Ep  8000 | Stage 2 (3T,4q) | Reward: -0.0016 | Error: 0.0016 | ε: 0.050\n",
            "Ep  8500 | Stage 2 (3T,4q) | Reward: -0.0015 | Error: 0.0015 | ε: 0.050\n",
            "Ep  9000 | Stage 2 (3T,4q) | Reward: -0.0014 | Error: 0.0014 | ε: 0.050\n",
            "Ep  9500 | Stage 2 (3T,4q) | Reward: -0.0015 | Error: 0.0015 | ε: 0.050\n",
            "Ep 10000 | Stage 2 (3T,4q) | Reward: -0.0017 | Error: 0.0017 | ε: 0.050\n",
            "Ep 10500 | Stage 3 (4T,4q) | Reward: -0.0016 | Error: 0.0016 | ε: 0.050\n",
            "Ep 11000 | Stage 3 (4T,4q) | Reward: -0.0009 | Error: 0.0009 | ε: 0.050\n",
            "Ep 11500 | Stage 3 (4T,4q) | Reward: -0.0009 | Error: 0.0009 | ε: 0.050\n",
            "Ep 12000 | Stage 3 (4T,4q) | Reward: -0.0011 | Error: 0.0011 | ε: 0.050\n",
            "Ep 12500 | Stage 3 (4T,4q) | Reward: -0.0011 | Error: 0.0011 | ε: 0.050\n",
            "Ep 13000 | Stage 3 (4T,4q) | Reward: -0.0010 | Error: 0.0010 | ε: 0.050\n",
            "Ep 13500 | Stage 3 (4T,4q) | Reward: -0.0011 | Error: 0.0011 | ε: 0.050\n",
            "Ep 14000 | Stage 3 (4T,4q) | Reward: -0.0013 | Error: 0.0013 | ε: 0.050\n",
            "Ep 14500 | Stage 3 (4T,4q) | Reward: -0.0008 | Error: 0.0008 | ε: 0.050\n",
            "Ep 15000 | Stage 3 (4T,4q) | Reward: -0.0013 | Error: 0.0013 | ε: 0.050\n",
            "Ep 15500 | Stage 4 (4T,4q) | Reward: -0.0013 | Error: 0.0013 | ε: 0.050\n",
            "Ep 16000 | Stage 4 (4T,4q) | Reward: -0.0012 | Error: 0.0012 | ε: 0.050\n",
            "Ep 16500 | Stage 4 (4T,4q) | Reward: -0.0014 | Error: 0.0014 | ε: 0.050\n",
            "Ep 17000 | Stage 4 (4T,4q) | Reward: -0.0011 | Error: 0.0011 | ε: 0.050\n",
            "Ep 17500 | Stage 4 (4T,4q) | Reward: -0.0013 | Error: 0.0013 | ε: 0.050\n",
            "Ep 18000 | Stage 4 (4T,4q) | Reward: -0.0008 | Error: 0.0008 | ε: 0.050\n",
            "Ep 18500 | Stage 4 (4T,4q) | Reward: -0.0012 | Error: 0.0012 | ε: 0.050\n",
            "Ep 19000 | Stage 4 (4T,4q) | Reward: -0.0013 | Error: 0.0013 | ε: 0.050\n",
            "Ep 19500 | Stage 4 (4T,4q) | Reward: -0.0013 | Error: 0.0013 | ε: 0.050\n",
            "Ep 20000 | Stage 4 (4T,4q) | Reward: -0.0009 | Error: 0.0009 | ε: 0.050\n",
            "Complete in 239.8m\n",
            "Action distribution (Top 5): {76: 642, 42: 607, 52: 578, 101: 561, 97: 510}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the filename for the checkpoint\n",
        "CHECKPOINT_PATH = '/content/zne_rl_agent_checkpoint.pth'\n",
        "\n",
        "# Save the model state dictionaries and other critical training parameters\n",
        "torch.save({\n",
        "    'q_network_state_dict': agent.q_network.state_dict(),\n",
        "    'target_network_state_dict': agent.target_network.state_dict(),\n",
        "    'optimizer_state_dict': agent.optimizer.state_dict(),\n",
        "    'epsilon': agent.epsilon,\n",
        "}, CHECKPOINT_PATH)\n",
        "\n",
        "print(f\"Model checkpoint successfully saved to {CHECKPOINT_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7cFf-Ada61q",
        "outputId": "1cfbb7d8-62cb-44c6-91b6-4813e7cb656e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint successfully saved to /content/zne_rl_agent_checkpoint.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "noisefactor_options = [\n",
        "    [1.0, 1.1, 1.2], [1.0, 1.2, 1.3], [1.0, 1.3, 1.5], [1.0, 1.4, 1.6],\n",
        "    [1.0, 1.5, 1.8], [1.0, 1.7, 1.9], [1.0, 2.0, 2.5], [1.0, 2.2, 2.7],\n",
        "    [1.0, 2.5, 2.9], [1, 2, 3], [1, 2, 4], [1, 3, 5],\n",
        "    [1.0, 3.0, 3.5], [1.0, 3.2, 3.8], [1.0, 3.5, 3.9], [1.0, 4.0, 5.0],\n",
        "    [1.0, 4.5, 5.0], [1, 3, 5, 7], [1, 5, 7], [1.0, 6.0, 7.0],\n",
        "    [1, 1.5, 2.5, 4], [1, 2, 3, 5], [1, 3, 5, 7], [1, 1.2, 2.5, 5],\n",
        "    [1, 1.5, 3, 7], [1.0, 1.8, 2.5], [1.0, 2.0, 3.5], [1.0, 3.0, 5.0],\n",
        "    [1.0, 2.5, 4.0], [1.0, 3.5, 6.0]\n",
        "]\n",
        "extrapolators = ['linear', 'polynomial', 'exponential', 'richardson']\n",
        "top_actions = {76: 642, 42: 607, 52: 578, 101: 561, 97: 510}\n",
        "\n",
        "print(\"## Policy Breakdown (Top 5 Actions)\")\n",
        "print(\"-----------------------------------\")\n",
        "print(f\"{'Rank':<4} | {'Action ID':<10} | {'Extrapolator':<15} | {'Noise Factors':<25} | {'Count':<5}\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "\n",
        "for rank, (action_id, count) in enumerate(top_actions.items(), 1):\n",
        "    action_id = int(action_id)\n",
        "\n",
        "    # Calculate Indices\n",
        "    extrap_index = action_id % len(extrapolators)\n",
        "    template_index = action_id // len(extrapolators)\n",
        "\n",
        "    # Retrieve Options\n",
        "    extrapolator_name = extrapolators[extrap_index]\n",
        "    factor_template = noisefactor_options[template_index]\n",
        "\n",
        "    print(f\"{rank:<4} | {action_id:<10} | {extrapolator_name:<15} | {str(factor_template):<25} | {count:<5}\")\n",
        "\n",
        "print(\"-----------------------------------\")\n",
        "print(\"Analysis: The agent favors high-density linear/polynomial extrapolation.\")"
      ],
      "metadata": {
        "id": "UUiTbjOUlY8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f037a7-d89a-4f93-f278-5d4f3b83ac56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Policy Breakdown (Top 5 Actions)\n",
            "-----------------------------------\n",
            "Rank | Action ID  | Extrapolator    | Noise Factors             | Count\n",
            "---------------------------------------------------------------------\n",
            "1    | 76         | linear          | [1.0, 6.0, 7.0]           | 642  \n",
            "2    | 42         | exponential     | [1, 2, 4]                 | 607  \n",
            "3    | 52         | linear          | [1.0, 3.2, 3.8]           | 578  \n",
            "4    | 101        | polynomial      | [1.0, 1.8, 2.5]           | 561  \n",
            "5    | 97         | polynomial      | [1, 1.5, 3, 7]            | 510  \n",
            "-----------------------------------\n",
            "Analysis: The agent favors high-density linear/polynomial extrapolation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "CHECKPOINT_FILENAME = 'zne_rl_agent_checkpoint.pth'\n",
        "\n",
        "# Check if the file already exists (e.g., if re-running the cell)\n",
        "if not os.path.exists(CHECKPOINT_FILENAME):\n",
        "    print(f\"Please upload your saved model file: {CHECKPOINT_FILENAME}\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if CHECKPOINT_FILENAME not in uploaded:\n",
        "        print(\"Upload failed or incorrect file name. Please try again.\")\n",
        "    else:\n",
        "        print(f\"File '{CHECKPOINT_FILENAME}' uploaded successfully.\")\n",
        "else:\n",
        "    print(f\"Checkpoint file '{CHECKPOINT_FILENAME}' already exists locally.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "kQ2FA4vBvWRW",
        "outputId": "1460702a-7cc1-4095-aaf3-b634badea68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your saved model file: zne_rl_agent_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fbdd35e2-cde1-416f-9e30-d063bc0ce399\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fbdd35e2-cde1-416f-9e30-d063bc0ce399\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving zne_rl_agent_checkpoint.pth to zne_rl_agent_checkpoint.pth\n",
            "File 'zne_rl_agent_checkpoint.pth' uploaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = '/content/zne_rl_agent_checkpoint.pth'\n",
        "\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    # Load the entire checkpoint dictionary\n",
        "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
        "\n",
        "    # Load weights into the Q-network and Target Network\n",
        "    agent.q_network.load_state_dict(checkpoint['q_network_state_dict'])\n",
        "    agent.target_network.load_state_dict(checkpoint['target_network_state_dict'])\n",
        "\n",
        "    # load the optimizer state, useful if resuming training\n",
        "    if 'optimizer_state_dict' in checkpoint:\n",
        "        agent.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    # Set epsilon to its last saved value, then immediately to 0 for testing\n",
        "    agent.epsilon = checkpoint.get('epsilon', 0.05)\n",
        "\n",
        "    # Ensure testing is done greedily\n",
        "    agent.epsilon = 0.0\n",
        "\n",
        "    print(\"Model weights loaded successfully.\")\n",
        "    print(\"Agent is set to greedy testing mode (epsilon=0.0).\")\n",
        "\n",
        "else:\n",
        "    print(f\" Error: Checkpoint file not found at {CHECKPOINT_PATH}. Please ensure you ran the upload block above.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42crWsgBvkGO",
        "outputId": "f5d04c9e-d699-4424-b06d-2d51e05ed158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights loaded successfully.\n",
            "Agent is set to greedy testing mode (epsilon=0.0).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_agent_final(env, agent, episodes=4000, curriculum_stages=4):\n",
        "\n",
        "    from collections import defaultdict\n",
        "    import time\n",
        "    import numpy as np\n",
        "\n",
        "    agent.epsilon = 0.0 # Set agent to greedy mode for testing\n",
        "\n",
        "    # --- Lists to Store All Errors and Actions ---\n",
        "    agent_errors = []\n",
        "    agent_actions = []\n",
        "    baseline_standard = []   # [1, 2, 3] Richardson\n",
        "    baseline_aggressive = [] # [1, 3, 5, 7] Richardson\n",
        "    baseline_fine = []       # [1.0, 1.1, 1.2] Linear\n",
        "    action_counts = defaultdict(int)\n",
        "\n",
        "    # Calculate curriculum details\n",
        "    episodes_per_stage = episodes // curriculum_stages\n",
        "    complexity_schedule = [(2, 4), (3, 4), (4, 4), (4, 4)]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"TESTING TRAINED AGENT ON {episodes} UNSEEN CIRCUITS\")\n",
        "    print(\"======================================================================\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Baselines Indices (Hardcoded from environment options)\n",
        "    ACT_STD = 9 * 4 + 3    # [1, 2, 3] Richardson\n",
        "    ACT_AGG = 17 * 4 + 3   # [1, 3, 5, 7] Richardson\n",
        "    ACT_FINE = 0           # [1.0, 1.1, 1.2] Linear\n",
        "\n",
        "    for stage in range(curriculum_stages):\n",
        "        trotter, nq = complexity_schedule[stage]\n",
        "\n",
        "        # --- ENFORCE CURRICULUM FOR TESTING ---\n",
        "        env.num_qubits = nq\n",
        "        env.trotter_steps = trotter\n",
        "\n",
        "        print(f\"Testing Stage {stage+1}/{curriculum_stages}: {episodes_per_stage} episodes at {trotter}T, {nq}q...\")\n",
        "\n",
        "        for ep in range(episodes_per_stage):\n",
        "            # Generate new circuit based on current stage complexity (NEAT runs inside reset)\n",
        "            state, _ = env.reset()\n",
        "\n",
        "            # 1. Agent's Action (Greedy)\n",
        "            agent_action = agent.select_action(state, training=False)\n",
        "            agent_actions.append(agent_action)\n",
        "            action_counts[agent_action] += 1\n",
        "            _, _, _, _, info_ag = env.step(agent_action)\n",
        "            agent_errors.append(info_ag['error'])\n",
        "\n",
        "            # 2. Baseline 1: Standard Richardson\n",
        "            _, _, _, _, info_std = env.step(ACT_STD)\n",
        "            baseline_standard.append(info_std['error'])\n",
        "\n",
        "            # 3. Baseline 2: Aggressive Richardson\n",
        "            _, _, _, _, info_agg = env.step(ACT_AGG)\n",
        "            baseline_aggressive.append(info_agg['error'])\n",
        "\n",
        "            # 4. Baseline 3: Fine Linear\n",
        "            _, _, _, _, info_fine = env.step(ACT_FINE)\n",
        "            baseline_fine.append(info_fine['error'])\n",
        "\n",
        "            if (ep + 1) % 500 == 0:\n",
        "                print(f\"  Progress: {ep+1} / {episodes_per_stage} tested.\")\n",
        "\n",
        "\n",
        "    test_time = (time.time() - start_time) / 60\n",
        "\n",
        "    # --- Final Statistics Calculation ---\n",
        "    agent_mean = np.mean(agent_errors)\n",
        "    agent_std = np.std(agent_errors)\n",
        "    agent_median = np.median(agent_errors)\n",
        "\n",
        "    std_mean = np.mean(baseline_standard)\n",
        "    agg_mean = np.mean(baseline_aggressive)\n",
        "    fine_mean = np.mean(baseline_fine)\n",
        "\n",
        "    vs_standard = (std_mean - agent_mean) / std_mean * 100\n",
        "    vs_aggressive = (agg_mean - agent_mean) / agg_mean * 100\n",
        "    vs_fine = (fine_mean - agent_mean) / fine_mean * 100\n",
        "\n",
        "    # --- Print Verbose Output ---\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"FINAL TEST RESULTS (Total {episodes} Circuits)\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Test Duration: {test_time:.1f} minutes\")\n",
        "    print(f\"\\nMean Error (± std | median):\")\n",
        "    print(f\"  Trained Agent:           {agent_mean:.4f} ± {agent_std:.4f} | {agent_median:.4f}\")\n",
        "    print(f\"  Baseline [1,2,3]+Rich:   {std_mean:.4f}\")\n",
        "    print(f\"  Baseline [1,3,5,7]+Rich: {agg_mean:.4f}\")\n",
        "    print(f\"  Baseline [1.0,1.1,1.2]+Lin: {fine_mean:.4f}\")\n",
        "\n",
        "    print(f\"\\nAgent Improvement:\")\n",
        "    print(f\"  vs [1,2,3]+Rich:   {vs_standard:+.2f}%\")\n",
        "    print(f\"  vs [1,3,5,7]+Rich: {vs_aggressive:+.2f}%\")\n",
        "    print(f\"  vs [1.0,1.1,1.2]+Lin: {vs_fine:+.2f}%\")\n",
        "\n",
        "    # Top actions\n",
        "    action_usage = np.zeros(agent.action_dim)\n",
        "    for a in agent_actions:\n",
        "        action_usage[a] += 1\n",
        "\n",
        "    top_5 = np.argsort(action_usage)[-5:][::-1]\n",
        "\n",
        "    print(f\"\\nTop 5 Actions Used by Agent:\")\n",
        "    for i, act_idx in enumerate(top_5, 1):\n",
        "        template_idx = act_idx // 4\n",
        "        extrap_idx = act_idx % 4\n",
        "        # Note: 'env.noisefactor_options' and 'env.extrapolators' must be accessible in scope\n",
        "        factors = env.noisefactor_options[template_idx]\n",
        "        extrap = env.extrapolators[extrap_idx]\n",
        "        count = int(action_usage[act_idx])\n",
        "        pct = count / episodes * 100\n",
        "        print(f\"  {i}. Action {act_idx}: {factors} + {extrap} ({count} uses, {pct:.2f}%)\")\n",
        "\n",
        "    print(\"======================================================================\")\n",
        "\n",
        "    return {\n",
        "        'agent_errors': agent_errors,\n",
        "        'agent_actions': agent_actions,\n",
        "        'baseline_standard': baseline_standard,\n",
        "        'baseline_aggressive': baseline_aggressive,\n",
        "        'baseline_fine': baseline_fine,\n",
        "        'agent_mean': agent_mean,\n",
        "        'std_mean': std_mean,\n",
        "        'agg_mean': agg_mean,\n",
        "        'fine_mean': fine_mean\n",
        "    }\n",
        "\n",
        "# Execute the testing function\n",
        "test_results = test_agent_final(env, agent, episodes=4000, curriculum_stages=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTGa4AdIJ9Kh",
        "outputId": "d12d23ca-8827-4954-9564-05d3a2994a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TESTING TRAINED AGENT ON 4000 UNSEEN CIRCUITS\n",
            "======================================================================\n",
            "Testing Stage 1/4: 1000 episodes at 2T, 4q...\n",
            "  Progress: 500 / 1000 tested.\n",
            "  Progress: 1000 / 1000 tested.\n",
            "Testing Stage 2/4: 1000 episodes at 3T, 4q...\n",
            "  Progress: 500 / 1000 tested.\n",
            "  Progress: 1000 / 1000 tested.\n",
            "Testing Stage 3/4: 1000 episodes at 4T, 4q...\n",
            "  Progress: 500 / 1000 tested.\n",
            "  Progress: 1000 / 1000 tested.\n",
            "Testing Stage 4/4: 1000 episodes at 4T, 4q...\n",
            "  Progress: 500 / 1000 tested.\n",
            "  Progress: 1000 / 1000 tested.\n",
            "\n",
            "======================================================================\n",
            "FINAL TEST RESULTS (Total 4000 Circuits)\n",
            "======================================================================\n",
            "Test Duration: 165.0 minutes\n",
            "\n",
            "Mean Error (± std | median):\n",
            "  Trained Agent:           0.0014 ± 0.0054 | 0.0000\n",
            "  Baseline [1,2,3]+Rich:   0.0014\n",
            "  Baseline [1,3,5,7]+Rich: 0.0014\n",
            "  Baseline [1.0,1.1,1.2]+Lin: 0.0015\n",
            "\n",
            "Agent Improvement:\n",
            "  vs [1,2,3]+Rich:   +0.88%\n",
            "  vs [1,3,5,7]+Rich: +2.20%\n",
            "  vs [1.0,1.1,1.2]+Lin: +5.52%\n",
            "\n",
            "Top 5 Actions Used by Agent:\n",
            "  1. Action 49: [1.0, 3.0, 3.5] + polynomial (4000 uses, 100.00%)\n",
            "  2. Action 119: [1.0, 3.5, 6.0] + richardson (0 uses, 0.00%)\n",
            "  3. Action 43: [1, 2, 4] + richardson (0 uses, 0.00%)\n",
            "  4. Action 31: [1.0, 2.2, 2.7] + richardson (0 uses, 0.00%)\n",
            "  5. Action 32: [1.0, 2.5, 2.9] + linear (0 uses, 0.00%)\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}