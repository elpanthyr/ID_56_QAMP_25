{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall -y qiskit qiskit-terra qiskit-aer qiskit-ibmq-provider qiskit-machine-learning qiskit-nature qiskit-finance qiskit-optimization\n"
      ],
      "metadata": {
        "id": "sk_zv1I8Wzda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install \"qiskit>=1.1.0\" \"qiskit-aer>=0.14.2\" torch numpy matplotlib scipy\n"
      ],
      "metadata": {
        "id": "hH2B5PPqW3RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import qiskit\n",
        "print(\"Qiskit version:\", qiskit.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0PMAElMXLsJ",
        "outputId": "4208131a-c4df-4149-9061-0c237c8d0dbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qiskit version: 2.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mitiq"
      ],
      "metadata": {
        "id": "t4_T6w2G0W80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "id": "EWxj_3wEA6hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'qiskit-addon-utils'"
      ],
      "metadata": {
        "id": "zaMOHLkcps4k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 0: Imports & dependency check\n",
        "import sys, os, math, time, copy, random\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import Qiskit + Aer;\n",
        "HAS_QISKIT = False\n",
        "HAS_AER = False\n",
        "try:\n",
        "    import qiskit\n",
        "    from qiskit import QuantumCircuit, transpile\n",
        "    from qiskit.providers.aer import AerSimulator\n",
        "    from qiskit.providers.aer.noise import NoiseModel\n",
        "    from qiskit.quantum_info import Statevector, Operator\n",
        "    HAS_QISKIT = True\n",
        "    try:\n",
        "        # Attempt to instantiate AerSimulator to ensure qiskit-aer available\n",
        "        _ = AerSimulator()\n",
        "        HAS_AER = True\n",
        "    except Exception:\n",
        "        HAS_AER = False\n",
        "except Exception:\n",
        "    HAS_QISKIT = False\n",
        "    HAS_AER = False\n",
        "\n",
        "# PyTorch for PPO\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    from torch.distributions import Categorical\n",
        "    HAS_TORCH = True\n",
        "except Exception:\n",
        "    HAS_TORCH = False\n",
        "\n",
        "print(\"HAS_QISKIT:\", HAS_QISKIT, \"HAS_AER:\", HAS_AER, \"HAS_TORCH:\", HAS_TORCH)\n",
        "if not (HAS_QISKIT and HAS_AER):\n",
        "    print(\"\\nNOTE: Qiskit/Aer not fully available. Cells that need realistic noise models will fall back to toy simulator.\")\n",
        "if not HAS_TORCH:\n",
        "    raise RuntimeError(\"PyTorch (torch) is required for the PPO implementation. Install with `pip install torch`.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JGZ_x54TmZE",
        "outputId": "4dd33f6e-c081-41de-f578-4e31c95528fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HAS_QISKIT: False HAS_AER: False HAS_TORCH: True\n",
            "\n",
            "NOTE: Qiskit/Aer not fully available. Cells that need realistic noise models will fall back to toy simulator.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Utility functions - extrapolators (linear, poly2, exponential)\n",
        "import warnings\n",
        "\n",
        "\n",
        "def linear_extrapolate(lambdas: List[float], values: List[float]) -> float:\n",
        "    if len(lambdas) < 2:\n",
        "        return values[0]\n",
        "    A = np.vstack([lambdas, np.ones_like(lambdas)]).T\n",
        "    sol, *_ = np.linalg.lstsq(A, values, rcond=None)\n",
        "    a, b = sol[0], sol[1]\n",
        "    return float(b)\n",
        "\n",
        "def poly2_extrapolate(lambdas: List[float], values: List[float]) -> float:\n",
        "    if len(lambdas) < 2:\n",
        "        return values[0]\n",
        "    A = np.vstack([np.array(lambdas)**2, np.array(lambdas), np.ones_like(lambdas)]).T\n",
        "    sol, *_ = np.linalg.lstsq(A, values, rcond=None)\n",
        "    return float(sol[2])\n",
        "\n",
        "def exponential_extrapolate(lambdas: List[float], values: List[float]) -> float:\n",
        "    lambdas = np.array(lambdas)\n",
        "    values = np.array(values)\n",
        "    minv = values.min()\n",
        "    shift = 0.0\n",
        "    if minv <= 0:\n",
        "        shift = 1e-8 - minv\n",
        "        values = values + shift\n",
        "    if len(lambdas) == 1:\n",
        "        return float(values[0] - shift)\n",
        "    try:\n",
        "        coefs = np.polyfit(lambdas, np.log(values), 1)\n",
        "        c = -coefs[0]\n",
        "        ln_b = coefs[1]\n",
        "        b = math.exp(ln_b)\n",
        "        return float(b - shift)\n",
        "    except Exception:\n",
        "        return float(values[0] - shift)\n",
        "\n",
        "EXTRAPOLATORS = {\n",
        "    0: (\"linear\", linear_extrapolate),\n",
        "    1: (\"poly2\", poly2_extrapolate),\n",
        "    2: (\"exponential\", exponential_extrapolate)\n",
        "}\n"
      ],
      "metadata": {
        "id": "4aCWcilzTxpD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Circuit generators - XYZ / TFIM Hamiltonian Trotterized circuits (Qiskit ≥1.0)\n",
        "import numpy as np\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.transpiler import CouplingMap\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit.circuit.library import PauliEvolutionGate\n",
        "from qiskit.synthesis import SuzukiTrotter\n",
        "\n",
        "def generate_xyz_hamiltonian_sparse(\n",
        "    n_qubits: int,\n",
        "    Jx: float = 0.4,\n",
        "    Jy: float = 0.4,\n",
        "    Jz: float = 0.0,\n",
        "    hx: float = 0.0,\n",
        "    hy: float = 0.0,\n",
        "    hz: float = 0.6\n",
        ") -> SparsePauliOp:\n",
        "    \"\"\"\n",
        "    Build an XYZ (or TFIM) Hamiltonian in SparsePauliOp form.\n",
        "\n",
        "    H = Σ_i [ Jx*X_i X_{i+1} + Jy*Y_i Y_{i+1} + Jz*Z_i Z_{i+1} ]\n",
        "        + Σ_i [ hx*X_i + hy*Y_i + hz*Z_i ]\n",
        "    with open boundary conditions.\n",
        "    \"\"\"\n",
        "    terms = []\n",
        "    coeffs = []\n",
        "\n",
        "    # two-qubit couplings\n",
        "    for i in range(n_qubits - 1):\n",
        "        if abs(Jx) > 1e-10:\n",
        "            pauli = [\"I\"] * n_qubits\n",
        "            pauli[i] = \"X\"\n",
        "            pauli[i + 1] = \"X\"\n",
        "            terms.append(\"\".join(pauli))\n",
        "            coeffs.append(Jx)\n",
        "        if abs(Jy) > 1e-10:\n",
        "            pauli = [\"I\"] * n_qubits\n",
        "            pauli[i] = \"Y\"\n",
        "            pauli[i + 1] = \"Y\"\n",
        "            terms.append(\"\".join(pauli))\n",
        "            coeffs.append(Jy)\n",
        "        if abs(Jz) > 1e-10:\n",
        "            pauli = [\"I\"] * n_qubits\n",
        "            pauli[i] = \"Z\"\n",
        "            pauli[i + 1] = \"Z\"\n",
        "            terms.append(\"\".join(pauli))\n",
        "            coeffs.append(Jz)\n",
        "\n",
        "    # single-qubit fields\n",
        "    for i in range(n_qubits):\n",
        "        if abs(hx) > 1e-10:\n",
        "            pauli = [\"I\"] * n_qubits\n",
        "            pauli[i] = \"X\"\n",
        "            terms.append(\"\".join(pauli))\n",
        "            coeffs.append(hx)\n",
        "        if abs(hy) > 1e-10:\n",
        "            pauli = [\"I\"] * n_qubits\n",
        "            pauli[i] = \"Y\"\n",
        "            terms.append(\"\".join(pauli))\n",
        "            coeffs.append(hy)\n",
        "        if abs(hz) > 1e-10:\n",
        "            pauli = [\"I\"] * n_qubits\n",
        "            pauli[i] = \"Z\"\n",
        "            terms.append(\"\".join(pauli))\n",
        "            coeffs.append(hz)\n",
        "\n",
        "    return SparsePauliOp.from_list(list(zip(terms, coeffs)))\n",
        "\n",
        "\n",
        "def xyz_trotter_circuit(\n",
        "    n_qubits: int = 4,\n",
        "    trotter_steps: int = 2,\n",
        "    dt: float = 0.1,\n",
        "    Jx: float = 0.4,\n",
        "    Jy: float = 0.4,\n",
        "    Jz: float = 0.0,\n",
        "    hx: float = 0.0,\n",
        "    hy: float = 0.0,\n",
        "    hz: float = 0.6,\n",
        "    with_measure: bool = False\n",
        ") -> QuantumCircuit:\n",
        "    \"\"\"\n",
        "    Build a Trotterized time-evolution circuit for the XYZ / TFIM Hamiltonian\n",
        "    using Qiskit 1.x `PauliEvolutionGate` (no deprecated opflow).\n",
        "\n",
        "    Args:\n",
        "        n_qubits: number of qubits.\n",
        "        trotter_steps: number of Trotter repetitions.\n",
        "        dt: time-step size.\n",
        "        Jx, Jy, Jz: coupling strengths.\n",
        "        hx, hy, hz: external field strengths.\n",
        "        with_measure: whether to append measurements.\n",
        "    \"\"\"\n",
        "    # Hamiltonian as SparsePauliOp\n",
        "    H = generate_xyz_hamiltonian_sparse(n_qubits, Jx, Jy, Jz, hx, hy, hz)\n",
        "\n",
        "    # Create the Trotter evolution gate using new synthesis interface\n",
        "    evo_gate = PauliEvolutionGate(\n",
        "        H,\n",
        "        time=dt,\n",
        "        synthesis=SuzukiTrotter(reps=1)  # single step per Trotter iteration\n",
        "    )\n",
        "\n",
        "    # Compose the evolution multiple times\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "    for _ in range(trotter_steps):\n",
        "        qc.append(evo_gate, range(n_qubits))\n",
        "\n",
        "    if with_measure:\n",
        "        qc.measure_all()\n",
        "\n",
        "    return qc\n",
        "\n",
        "\n",
        "# --- Example test: small TFIM circuit ---\n",
        "qc_test = xyz_trotter_circuit(n_qubits=3, trotter_steps=2, dt=0.1, Jx=0.5, hz=0.7, with_measure=True)\n",
        "print(qc_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1rJVI_s3ZyS",
        "outputId": "ad5930c4-0515-40c6-9da1-0c60e88b559c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ┌──────────────────────────────────────────────────────────┐»\n",
            "   q_0: ┤0                                                         ├»\n",
            "        │                                                          │»\n",
            "   q_1: ┤1 exp(-it (XXI + YYI + IXX + IYY + ZII + IZI + IIZ))(0.1) ├»\n",
            "        │                                                          │»\n",
            "   q_2: ┤2                                                         ├»\n",
            "        └──────────────────────────────────────────────────────────┘»\n",
            "meas: 3/════════════════════════════════════════════════════════════»\n",
            "                                                                    »\n",
            "«        ┌──────────────────────────────────────────────────────────┐ ░ ┌─┐   »\n",
            "«   q_0: ┤0                                                         ├─░─┤M├───»\n",
            "«        │                                                          │ ░ └╥┘┌─┐»\n",
            "«   q_1: ┤1 exp(-it (XXI + YYI + IXX + IYY + ZII + IZI + IIZ))(0.1) ├─░──╫─┤M├»\n",
            "«        │                                                          │ ░  ║ └╥┘»\n",
            "«   q_2: ┤2                                                         ├─░──╫──╫─»\n",
            "«        └──────────────────────────────────────────────────────────┘ ░  ║  ║ »\n",
            "«meas: 3/════════════════════════════════════════════════════════════════╩══╩═»\n",
            "«                                                                        0  1 »\n",
            "«           \n",
            "«   q_0: ───\n",
            "«           \n",
            "«   q_1: ───\n",
            "«        ┌─┐\n",
            "«   q_2: ┤M├\n",
            "«        └╥┘\n",
            "«meas: 3/═╩═\n",
            "«         2 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Circuit folding, mirrored, and Cliffordized utilities (Qiskit ≥1.0)\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    from qiskit import QuantumCircuit\n",
        "    from qiskit.converters import circuit_to_dag, dag_to_circuit\n",
        "    from qiskit.quantum_info import Clifford, SparsePauliOp\n",
        "    HAS_QISKIT = True\n",
        "except Exception:\n",
        "    HAS_QISKIT = False\n",
        "\n",
        "\n",
        "def fold_circuit(qc: \"QuantumCircuit\", lam: float) -> \"QuantumCircuit\":\n",
        "    r\"\"\"\n",
        "    Fold circuit to amplify noise.\n",
        "\n",
        "    For a digital fold factor λ (e.g., 2.0), we repeat the unitary and its inverse\n",
        "    to increase the number of gates, while preserving the logical function.\n",
        "\n",
        "    Implementation:\n",
        "      folded = U + (U U†) * (k-1) + optionally partial folding for fractional λ.\n",
        "\n",
        "    Args:\n",
        "        qc: Base QuantumCircuit.\n",
        "        lam: Folding factor λ ≥ 1.\n",
        "    \"\"\"\n",
        "    if not HAS_QISKIT:\n",
        "        return {\"folded_from\": qc, \"lam\": lam}\n",
        "\n",
        "    lam = float(lam)\n",
        "    if lam <= 1.0:\n",
        "        return qc.copy()\n",
        "\n",
        "    k = int(math.floor(lam))\n",
        "    frac = lam - k\n",
        "\n",
        "    folded = qc.copy()\n",
        "    # Integer folds: repeat U U† pairs\n",
        "    for _ in range(max(0, k - 1)):\n",
        "        folded = folded.compose(qc.inverse()).compose(qc)\n",
        "\n",
        "    # Fractional folding\n",
        "    if frac > 1e-8:\n",
        "        dag = circuit_to_dag(qc)\n",
        "        nodes = list(dag.topological_op_nodes())\n",
        "        p = max(1, int(len(nodes) * frac))\n",
        "        partial = QuantumCircuit(qc.num_qubits)\n",
        "        for n in nodes[:p]:\n",
        "            partial.append(n.op, n.qargs, n.cargs)\n",
        "        folded = folded.compose(partial.inverse()).compose(partial)\n",
        "\n",
        "    return folded\n",
        "\n",
        "\n",
        "def mirror_circuit(qc: \"QuantumCircuit\") -> \"QuantumCircuit\":\n",
        "    r\"\"\"\n",
        "    Create a mirrored circuit: U followed by U†.\n",
        "\n",
        "    This construction has a known ideal expectation (often +1 on certain observables),\n",
        "    which makes it useful for calibration or benchmarking.\n",
        "\n",
        "    Args:\n",
        "        qc: Input circuit.\n",
        "    \"\"\"\n",
        "    if not HAS_QISKIT:\n",
        "        return {\"mirrored_from\": qc}\n",
        "\n",
        "    mirrored = qc.copy()\n",
        "    mirrored = mirrored.compose(qc.inverse())\n",
        "    return mirrored\n",
        "\n",
        "\n",
        "def cliffordize_circuit(qc: \"QuantumCircuit\") -> \"QuantumCircuit\":\n",
        "    r\"\"\"\n",
        "    Replace non-Clifford gates with approximate Clifford equivalents.\n",
        "\n",
        "    This creates a circuit that can be simulated efficiently\n",
        "    with stabilizer simulators. We approximate RX/RY/RZ gates\n",
        "    whose angles are near multiples of π/2 as exact Clifford gates.\n",
        "\n",
        "    Args:\n",
        "        qc: Input QuantumCircuit.\n",
        "    \"\"\"\n",
        "    if not HAS_QISKIT:\n",
        "        return {\"cliffordized_from\": qc}\n",
        "\n",
        "    new_qc = QuantumCircuit(qc.num_qubits)\n",
        "\n",
        "    for instr, qargs, cargs in qc.data:\n",
        "        name = instr.name.lower()\n",
        "        if name in (\"rx\", \"ry\", \"rz\"):\n",
        "            theta = float(instr.params[0])\n",
        "            ratio = theta / (np.pi / 2)\n",
        "            nearest = round(ratio)\n",
        "            if abs(ratio - nearest) < 0.05:  # \"close enough\" to Clifford\n",
        "                theta_cliff = nearest * (np.pi / 2)\n",
        "                new_qc.append(instr.__class__(theta_cliff), qargs, cargs)\n",
        "            else:\n",
        "                new_qc.append(instr, qargs, cargs)\n",
        "        else:\n",
        "            new_qc.append(instr, qargs, cargs)\n",
        "\n",
        "    return new_qc\n"
      ],
      "metadata": {
        "id": "Ye_hggLJ3wK7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qc = QuantumCircuit(2)\n",
        "qc.h(0)\n",
        "qc.cx(0, 1)\n",
        "\n",
        "folded_qc = fold_circuit(qc, 2.5)\n",
        "mirrored_qc = mirror_circuit(qc)\n",
        "cliff_qc = cliffordize_circuit(qc)\n",
        "\n",
        "print(\"Folded circuit:\")\n",
        "print(folded_qc.draw())\n",
        "print(\"\\nMirrored circuit:\")\n",
        "print(mirrored_qc.draw())\n",
        "print(\"\\nCliffordized circuit:\")\n",
        "print(cliff_qc.draw())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpLZnYnT30QZ",
        "outputId": "da08d908-c810-4191-e059-ba4a222dff95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folded circuit:\n",
            "     ┌───┐          ┌───┐┌───┐     ┌───┐┌───┐\n",
            "q_0: ┤ H ├──■────■──┤ H ├┤ H ├──■──┤ H ├┤ H ├\n",
            "     └───┘┌─┴─┐┌─┴─┐└───┘└───┘┌─┴─┐└───┘└───┘\n",
            "q_1: ─────┤ X ├┤ X ├──────────┤ X ├──────────\n",
            "          └───┘└───┘          └───┘          \n",
            "\n",
            "Mirrored circuit:\n",
            "     ┌───┐          ┌───┐\n",
            "q_0: ┤ H ├──■────■──┤ H ├\n",
            "     └───┘┌─┴─┐┌─┴─┐└───┘\n",
            "q_1: ─────┤ X ├┤ X ├─────\n",
            "          └───┘└───┘     \n",
            "\n",
            "Cliffordized circuit:\n",
            "     ┌───┐     \n",
            "q_0: ┤ H ├──■──\n",
            "     └───┘┌─┴─┐\n",
            "q_1: ─────┤ X ├\n",
            "          └───┘\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3347026808.py:90: DeprecationWarning: Treating CircuitInstruction as an iterable is deprecated legacy behavior since Qiskit 1.2, and will be removed in Qiskit 3.0. Instead, use the `operation`, `qubits` and `clbits` named attributes.\n",
            "  for instr, qargs, cargs in qc.data:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import math\n",
        "# import random\n",
        "# from dataclasses import dataclass\n",
        "# from typing import Optional, List, Dict\n",
        "# HAS_QISKIT = False\n",
        "# HAS_AER = False\n",
        "# QC_CLASS = None\n",
        "# StatevectorClass = None\n",
        "# transpile = None\n",
        "# NoiseModelClass = None\n",
        "# AerSimulatorClass = None\n",
        "# fold_circuit_func = None\n",
        "\n",
        "# try:\n",
        "#     import qiskit\n",
        "#     from qiskit import QuantumCircuit\n",
        "#     from qiskit import transpile as _transpile\n",
        "#     from qiskit.quantum_info import Statevector\n",
        "#     from qiskit.providers.aer import AerSimulator\n",
        "#     from qiskit.providers.aer.noise import NoiseModel\n",
        "#     # bind safely\n",
        "#     HAS_QISKIT = True\n",
        "#     try:\n",
        "#         _ = AerSimulator()\n",
        "#         HAS_AER = True\n",
        "#     except Exception:\n",
        "#         HAS_AER = False\n",
        "#     QC_CLASS = QuantumCircuit\n",
        "#     StatevectorClass = Statevector\n",
        "#     transpile = _transpile\n",
        "#     NoiseModelClass = NoiseModel\n",
        "#     AerSimulatorClass = AerSimulator\n",
        "\n",
        "#     # Fold & mirroring helpers\n",
        "#     def fold_circuit(qc, lam: float):\n",
        "#         \"\"\"Lightweight folding using QC.copy() and concatenation.\n",
        "#         if not isinstance(qc, QC_CLASS):\n",
        "#             return qc\n",
        "#         lam = float(lam)\n",
        "#         k = int(math.floor(lam))\n",
        "#         frac = lam - k\n",
        "#         folded = qc.copy()\n",
        "#         # append U U^\\dagger pairs to increase gate count without changing logical op\n",
        "#         for _ in range(max(0, k - 1)):\n",
        "#             folded = folded + qc.inverse() + qc\n",
        "#         if frac > 1e-8:\n",
        "#             # append a small partial repetition using the first few operations\n",
        "#             try:\n",
        "#                 from qiskit.converters import circuit_to_dag\n",
        "#                 dag = circuit_to_dag(qc)\n",
        "#                 nodes = list(dag.topological_op_nodes())\n",
        "#                 p = max(1, int(len(nodes) * frac))\n",
        "#                 partial = QC_CLASS(qc.num_qubits)\n",
        "#                 for n in nodes[:p]:\n",
        "#                     partial.append(n.op, n.qargs, n.cargs)\n",
        "#                 folded = folded + partial.inverse() + partial\n",
        "#             except Exception:\n",
        "#                 # fallback: duplicate entire qc once\n",
        "#                 folded = folded + qc.inverse() + qc\n",
        "#         return folded\n",
        "\n",
        "#     fold_circuit_func = fold_circuit\n",
        "\n",
        "# except Exception:\n",
        "#     # Qiskit not available — prepare placeholders\n",
        "#     HAS_QISKIT = False\n",
        "#     HAS_AER = False\n",
        "#     QC_CLASS = None\n",
        "#     StatevectorClass = None\n",
        "#     transpile = lambda qc, **kwargs: qc\n",
        "#     NoiseModelClass = None\n",
        "#     AerSimulatorClass = None\n",
        "\n",
        "#     : keeps descriptor as-is\n",
        "#     def fold_circuit_placeholder(qc, lam: float):\n",
        "#         return {\"folded_from\": qc, \"lam\": lam}\n",
        "#     fold_circuit_func = fold_circuit_placeholder\n",
        "\n",
        "# # ---------------------------\n",
        "# # Extrapolators (small set)\n",
        "# # ---------------------------\n",
        "# def linear_extrapolate(lambdas: List[float], values: List[float]) -> float:\n",
        "#     if len(lambdas) < 2:\n",
        "#         return float(values[0])\n",
        "#     A = np.vstack([lambdas, np.ones_like(lambdas)]).T\n",
        "#     sol, *_ = np.linalg.lstsq(A, values, rcond=None)\n",
        "#     a, b = sol[0], sol[1]\n",
        "#     return float(b)\n",
        "\n",
        "# def poly2_extrapolate(lambdas: List[float], values: List[float]) -> float:\n",
        "#     if len(lambdas) < 2:\n",
        "#         return float(values[0])\n",
        "#     A = np.vstack([np.array(lambdas)**2, np.array(lambdas), np.ones_like(lambdas)]).T\n",
        "#     sol, *_ = np.linalg.lstsq(A, values, rcond=None)\n",
        "#     return float(sol[2])\n",
        "\n",
        "# def exponential_extrapolate(lambdas: List[float], values: List[float]) -> float:\n",
        "#     lambdas = np.array(lambdas)\n",
        "#     values = np.array(values, dtype=float)\n",
        "#     minv = values.min()\n",
        "#     shift = 0.0\n",
        "#     if minv <= 0:\n",
        "#         shift = 1e-8 - minv\n",
        "#         values = values + shift\n",
        "#     if len(lambdas) == 1:\n",
        "#         return float(values[0] - shift)\n",
        "#     try:\n",
        "#         coefs = np.polyfit(lambdas, np.log(values), 1)\n",
        "#         ln_b = coefs[1]\n",
        "#         b = math.exp(ln_b)\n",
        "#         return float(b - shift)\n",
        "#     except Exception:\n",
        "#         return float(values[0] - shift)\n",
        "\n",
        "# EXTRAPOLATORS = {\n",
        "#     0: (\"linear\", linear_extrapolate),\n",
        "#     1: (\"poly2\", poly2_extrapolate),\n",
        "#     2: (\"exponential\", exponential_extrapolate)\n",
        "# }\n",
        "\n",
        "# # ---------------------------\n",
        "# # Data classes\n",
        "# # ---------------------------\n",
        "# @dataclass\n",
        "# class HardwareProfile:\n",
        "#     name: str\n",
        "#     t1: float\n",
        "#     two_q_time: float\n",
        "#     base_error: float\n",
        "\n",
        "# @dataclass\n",
        "# class CircuitFeatures:\n",
        "#     n_qubits: int\n",
        "#     two_q_count: int\n",
        "#     two_q_depth: int\n",
        "#     trotter_steps: int\n",
        "\n",
        "# # ---------------------------\n",
        "# # ---------------------------\n",
        "# class ZNEEnvQiskit:\n",
        "#     def __init__(self,\n",
        "#                  qc_or_desc,\n",
        "#                  hw: HardwareProfile,\n",
        "#                  pool: Optional[List[float]] = None,\n",
        "#                  max_folds: int = 4,\n",
        "#                  alpha: float = 0.1,\n",
        "#                  shots: int = 2048):\n",
        "#         self.has_qiskit = HAS_QISKIT and HAS_AER\n",
        "#         self.qc_desc = qc_or_desc\n",
        "#         self.hw = hw\n",
        "#         self.alpha = alpha\n",
        "#         self.max_folds = max_folds\n",
        "#         self.shots = shots\n",
        "#         if pool is None:\n",
        "#             pool = [1.0, 1.2, 1.5, 2.0, 3.0]\n",
        "#         self.pool = self._prescreen(pool)\n",
        "#         self.E = len(EXTRAPOLATORS)\n",
        "#         self.ACTIONS_PER_STEP = len(self.pool) + 1  # pool choices + STOP\n",
        "#         self.extrap_idx = None\n",
        "#         self.selected = []\n",
        "#         self.done = False\n",
        "#         self.ideal = 0.0\n",
        "#         # reset will compute ideal\n",
        "#         self.reset()\n",
        "\n",
        "#     def _prescreen(self, pool: List[float]) -> List[float]:\n",
        "#         # If no Qiskit, use descriptor fallback using a simple depth estimate\n",
        "#         try:\n",
        "#             if HAS_QISKIT and (QC_CLASS is not None) and isinstance(self.qc_desc, QC_CLASS):\n",
        "#                 # try to get depth via transpile\n",
        "#                 t_qc = transpile(self.qc_desc, optimization_level=0)\n",
        "#                 depth = getattr(t_qc, \"depth\", lambda: 1)()\n",
        "#             elif isinstance(self.qc_desc, dict):\n",
        "#                 depth = self.qc_desc.get(\"steps\", 1) * max(1, self.qc_desc.get(\"n\", 4))\n",
        "#             else:\n",
        "#                 depth = 1\n",
        "#         except Exception:\n",
        "#             depth = 1\n",
        "#         f = 0.9\n",
        "#         res = [lam for lam in pool if lam * depth * self.hw.two_q_time <= f * self.hw.t1]\n",
        "#         if 1.0 not in res:\n",
        "#             res = [1.0] + res\n",
        "#         return sorted(set(res))\n",
        "\n",
        "#     def reset(self):\n",
        "#         # reset internal state; compute ideal expectation if possible\n",
        "#         self.extrap_idx = None\n",
        "#         self.selected = []\n",
        "#         self.done = False\n",
        "#         # compute ideal expectation\n",
        "#         try:\n",
        "#             if HAS_QISKIT and (QC_CLASS is not None) and isinstance(self.qc_desc, QC_CLASS):\n",
        "#                 # remove measurements safely (if present)\n",
        "#                 try:\n",
        "#                     qc_nom = self.qc_desc.remove_final_measurements(inplace=False)\n",
        "#                 except Exception:\n",
        "#                     qc_nom = self.qc_desc\n",
        "#                 # Compute statevector and expectation of Z on qubit 0\n",
        "#                 try:\n",
        "#                     sv = StatevectorClass.from_instruction(qc_nom)\n",
        "#                     probs = np.abs(sv.data) ** 2\n",
        "#                     expect = 0.0\n",
        "#                     for idx, p in enumerate(probs):\n",
        "#                         b0 = (idx >> 0) & 1\n",
        "#                         expect += ((-1) ** b0) * p\n",
        "#                     self.ideal = float(expect)\n",
        "#                 except Exception:\n",
        "#                     # fallback analytic if statevector failed\n",
        "#                     self.ideal = self._analytic_ideal_from_desc()\n",
        "#             else:\n",
        "#                 self.ideal = self._analytic_ideal_from_desc()\n",
        "#         except Exception:\n",
        "#             self.ideal = self._analytic_ideal_from_desc()\n",
        "#         return self._observation()\n",
        "\n",
        "#     def _analytic_ideal_from_desc(self):\n",
        "#         # rough analytic ideal for descriptor circuits\n",
        "#         if isinstance(self.qc_desc, dict):\n",
        "#             n = self.qc_desc.get(\"n\", 4)\n",
        "#             steps = self.qc_desc.get(\"steps\", 1)\n",
        "#             energy = 1.0 + 0.1 * (n - 4)\n",
        "#             t = max(0.1, 0.5 * steps)\n",
        "#             return float(max(-1.0, min(1.0, math.cos(energy * t))))\n",
        "#         return 0.0\n",
        "\n",
        "#     def _compute_observable_expectation(self, sv, n_qubits: int):\n",
        "#         probs = np.abs(sv.data) ** 2\n",
        "#         expect = 0.0\n",
        "#         for idx, p in enumerate(probs):\n",
        "#             b0 = (idx >> 0) & 1\n",
        "#             expect += ((-1) ** b0) * p\n",
        "#         return float(expect)\n",
        "\n",
        "#     def _simulate_qiskit_noisy(self, qc, lam: float) -> float:\n",
        "#         # If Qiskit/Aer not available, use analytic decay model\n",
        "#         if not (HAS_QISKIT and HAS_AER and (QC_CLASS is not None)):\n",
        "#             decay = self.hw.base_error * (1.0 + 0.01 * len(self.selected)) * lam\n",
        "#             noisy = self.ideal * math.exp(-decay) + np.random.normal(scale=0.01)\n",
        "#             return float(max(-1.0, min(1.0, noisy)))\n",
        "\n",
        "#         # If qc is a descriptor but not a real QuantumCircuit, fall back to analytic\n",
        "#         if not isinstance(self.qc_desc, QC_CLASS):\n",
        "#             decay = self.hw.base_error * lam\n",
        "#             noisy = self.ideal * math.exp(-decay) + np.random.normal(scale=0.01)\n",
        "#             return float(max(-1.0, min(1.0, noisy)))\n",
        "\n",
        "#         # Build folded circuit via helper\n",
        "#         folded = fold_circuit_func(self.qc_desc, lam)\n",
        "\n",
        "#         # Build a lightweight noise model; if unavailable, run noiseless density-matrix sim and add analytic noise\n",
        "#         try:\n",
        "#             noise = NoiseModelClass()\n",
        "#             sim = AerSimulatorClass(method='density_matrix')\n",
        "#             t_qc = transpile(folded, sim)\n",
        "#             job = sim.run(t_qc, noise_model=noise, shots=self.shots)\n",
        "#             res = job.result()\n",
        "#             counts = res.get_counts()\n",
        "#             mean = 0.0\n",
        "#             total = sum(counts.values()) if counts else 1\n",
        "#             for bitstr, c in counts.items():\n",
        "#                 b0 = int(bitstr[-1])\n",
        "#                 mean += ((-1) ** b0) * (c / total)\n",
        "#             return float(mean)\n",
        "#         except Exception:\n",
        "#             # fallback analytic if Aer/NoiseModel call fails\n",
        "#             decay = self.hw.base_error * lam\n",
        "#             noisy = self.ideal * math.exp(-decay) + np.random.normal(scale=0.01)\n",
        "#             return float(max(-1.0, min(1.0, noisy)))\n",
        "\n",
        "#     def _run_zne(self, extrap_idx: int, lambdas: List[float]):\n",
        "#         vals = [self._simulate_qiskit_noisy(self.qc_desc if (HAS_QISKIT and isinstance(self.qc_desc, QC_CLASS)) else None, l) for l in lambdas]\n",
        "#         est = EXTRAPOLATORS[extrap_idx][1](lambdas, vals)\n",
        "#         return est, vals\n",
        "\n",
        "#     def _observation(self):\n",
        "#         # create a compact feature vector\n",
        "#         if isinstance(self.qc_desc, dict):\n",
        "#             n = self.qc_desc.get(\"n\", 4)\n",
        "#             steps = self.qc_desc.get(\"steps\", 1)\n",
        "#             depth = int(n * steps)\n",
        "#         else:\n",
        "#             try:\n",
        "#                 depth = getattr(self.qc_desc, \"depth\", lambda: 1)()\n",
        "#                 n = getattr(self.qc_desc, \"num_qubits\", 4)\n",
        "#                 steps = max(1, depth // max(1, n))\n",
        "#             except Exception:\n",
        "#                 depth = 1; n = 4; steps = 1\n",
        "#         fv = [\n",
        "#             float(n), float(depth), float(steps),\n",
        "#             float(self.hw.t1), float(self.hw.two_q_time), float(self.hw.base_error),\n",
        "#             float(len(self.selected)), float(sum(self.selected) if self.selected else 0.0)\n",
        "#         ]\n",
        "#         pool_pad = list(_\n"
      ],
      "metadata": {
        "id": "htAXJHJq0LVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust Mitiq ZNE helper functions (execute_with_zne + decorators)\n",
        "from typing import Callable, Sequence, List, Optional, Union\n",
        "from collections.abc import Iterable\n",
        "import math\n",
        "\n",
        "from mitiq import QPROGRAM, Executor as MitiqExecutor, Observable, QuantumResult\n",
        "from mitiq.zne.inference import Factory, RichardsonFactory\n",
        "from mitiq.zne.scaling import fold_gates_at_random\n",
        "\n",
        "# --- construct_circuits (keeps original semantics) ---\n",
        "def construct_circuits(\n",
        "    circuit: QPROGRAM,\n",
        "    scale_factors: Sequence[float],\n",
        "    scale_method: Callable[[QPROGRAM, float], QPROGRAM] = fold_gates_at_random,  # type: ignore[has-type]\n",
        ") -> List[QPROGRAM]:\n",
        "    \"\"\"Given a circuit and scale_factors, returns scaled circuits using scale_method.\"\"\"\n",
        "    if not isinstance(scale_factors, Iterable):\n",
        "        raise TypeError(\"scale_factors must be an iterable of floats.\")\n",
        "    circuits = [scale_method(circuit, float(sf)) for sf in scale_factors]\n",
        "    return circuits\n",
        "\n",
        "\n",
        "# --- combine_results (thin wrapper around chosen extrapolation callable) ---\n",
        "def combine_results(\n",
        "    scale_factors: Sequence[float],\n",
        "    results: Sequence[float],\n",
        "    extrapolation_method: Callable[[Sequence[float], Sequence[float]], float],\n",
        ") -> float:\n",
        "    \"\"\"Apply an extrapolation method (callable) to produce the final ZNE estimate.\"\"\"\n",
        "    if len(scale_factors) != len(results):\n",
        "        raise ValueError(\"scale_factors and results must have the same length.\")\n",
        "    return float(extrapolation_method(scale_factors, results))\n",
        "\n",
        "\n",
        "# --- helper: call executor in a robust way ---\n",
        "def _call_executor_single(\n",
        "    executor: Union[Callable[[QPROGRAM], QuantumResult], MitiqExecutor],\n",
        "    circuit: QPROGRAM,\n",
        ") -> QuantumResult:\n",
        "    \"\"\"\n",
        "    Best-effort wrapper that calls 'executor' on a single circuit and returns a QuantumResult-like object\n",
        "    or numeric expectation. Supports plain callables and Mitiq Executor-like wrappers.\n",
        "    \"\"\"\n",
        "    # If user passed an actual mitiq.Executor instance, prefer its 'execute' or 'run' if available.\n",
        "    try:\n",
        "        # If executor is a MitiqExecutor object, try methods commonly exposed\n",
        "        if isinstance(executor, MitiqExecutor):\n",
        "            # try batch execution first if it supports it\n",
        "            if getattr(executor, \"can_batch\", False):\n",
        "                # some Executor implementations offer .execute(circ) or .run(circ) — try both\n",
        "                if hasattr(executor, \"execute\"):\n",
        "                    return executor.execute(circuit)\n",
        "                elif hasattr(executor, \"run\"):\n",
        "                    return executor.run([circuit])\n",
        "                else:\n",
        "                    # fallback to calling as callable\n",
        "                    return executor(circuit)\n",
        "            else:\n",
        "                # not batch-capable: try execute or call directly\n",
        "                if hasattr(executor, \"execute\"):\n",
        "                    return executor.execute(circuit)\n",
        "                else:\n",
        "                    return executor(circuit)\n",
        "    except Exception:\n",
        "        # If the above path fails, fall through to treating executor as simple callable.\n",
        "        pass\n",
        "\n",
        "    # Finally, attempt to call executor as a plain callable\n",
        "    result = executor(circuit)\n",
        "    return result\n",
        "\n",
        "\n",
        "# --- main function: execute_with_zne ---\n",
        "def execute_with_zne(\n",
        "    circuit: QPROGRAM,\n",
        "    executor: Union[Callable[[QPROGRAM], Union[QuantumResult, float]], MitiqExecutor],\n",
        "    observable: Optional[Observable] = None,\n",
        "    *,\n",
        "    factory: Optional[Factory] = None,\n",
        "    scale_noise: Callable[[QPROGRAM, float], QPROGRAM] = fold_gates_at_random,  # type: ignore[has-type]\n",
        "    num_to_average: int = 1,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Estimate the error-mitigated expectation value for `circuit` using ZNE.\n",
        "\n",
        "    Args:\n",
        "        circuit: input circuit (QPROGRAM).\n",
        "        executor: a callable that accepts a circuit and returns either:\n",
        "                  - a numeric expectation (float), or\n",
        "                  - a QuantumResult-like object (object with numeric .value/.values or convertible to float).\n",
        "                  Alternatively, a mitiq.Executor instance may be supplied (best-effort support).\n",
        "        observable: optional Observable — if provided, the executor's QuantumResult is used to compute\n",
        "                    the observable expectation. If None, the executor must already return an expectation.\n",
        "        factory: a mitiq Factory (e.g. RichardsonFactory, PolyFactory). If None, defaults to RichardsonFactory([1,2,3]).\n",
        "        scale_noise: a function (circuit, scale_factor) -> scaled circuit (e.g. fold_gates_at_random).\n",
        "        num_to_average: times to run each scaled circuit and average the returned expectation.\n",
        "\n",
        "    Returns:\n",
        "        float: the error-mitigated expectation.\n",
        "    \"\"\"\n",
        "    # Validate inputs\n",
        "    if num_to_average < 1:\n",
        "        raise ValueError(\"num_to_average must be >= 1.\")\n",
        "    if not callable(scale_noise):\n",
        "        raise TypeError(\"scale_noise must be callable.\")\n",
        "\n",
        "    # Default factory\n",
        "    if factory is None:\n",
        "        factory = RichardsonFactory(scale_factors=[1.0, 2.0, 3.0])\n",
        "\n",
        "    if not isinstance(factory, Factory):\n",
        "        raise TypeError(\"factory must be an instance of mitiq.zne.inference.Factory (or subclass).\")\n",
        "\n",
        "    # Determine scale factors to use:\n",
        "    # Prefer factory.scale_factors if present; else try attribute names used by specific factories.\n",
        "    scale_factors = None\n",
        "    if hasattr(factory, \"scale_factors\"):\n",
        "        scale_factors = getattr(factory, \"scale_factors\")\n",
        "    elif hasattr(factory, \"_scale_factors\"):\n",
        "        scale_factors = getattr(factory, \"_scale_factors\")\n",
        "    # Always ensure we have a list\n",
        "    if scale_factors is None:\n",
        "        # fallback to the common default\n",
        "        scale_factors = [1.0, 2.0, 3.0]\n",
        "    scale_factors = list(map(float, scale_factors))\n",
        "    if len(scale_factors) < 1:\n",
        "        raise ValueError(\"factory must provide at least one scale factor.\")\n",
        "\n",
        "    # Build scaled circuits using provided scale_noise function\n",
        "    scaled_circuits = construct_circuits(circuit, scale_factors, scale_noise)\n",
        "\n",
        "    # Execute each scaled circuit (with averaging) and extract expectation values\n",
        "    results: List[float] = []\n",
        "    for idx, scaled in enumerate(scaled_circuits):\n",
        "        vals_for_scale = []\n",
        "        for _ in range(num_to_average):\n",
        "            raw = _call_executor_single(executor, scaled)\n",
        "\n",
        "            # interpret the returned raw object:\n",
        "            # - If it's numeric (float or numpy scalar), accept it\n",
        "            # - If it's a QuantumResult-like object, try to extract a numeric value:\n",
        "            #     * If has attribute 'value' or 'values', use it.\n",
        "            #     * If it's a dict-like (quasi-distribution), attempt to compute expectation of Z on qubit 0 if observable is None.\n",
        "            val = None\n",
        "            # numeric case\n",
        "            if isinstance(raw, (int, float)):\n",
        "                val = float(raw)\n",
        "            else:\n",
        "                # try common QuantumResult patterns\n",
        "                # prefer .value / .values\n",
        "                if hasattr(raw, \"value\"):\n",
        "                    try:\n",
        "                        val = float(raw.value)\n",
        "                    except Exception:\n",
        "                        # if it's iterable, take first element\n",
        "                        try:\n",
        "                            val = float(raw.value[0])\n",
        "                        except Exception:\n",
        "                            val = None\n",
        "                elif hasattr(raw, \"values\"):\n",
        "                    try:\n",
        "                        v = raw.values\n",
        "                        # conversion for numpy arrays\n",
        "                        if hasattr(v, \"__len__\") and len(v) > 0:\n",
        "                            val = float(v[0])\n",
        "                        else:\n",
        "                            val = float(v)\n",
        "                    except Exception:\n",
        "                        val = None\n",
        "                elif isinstance(raw, dict):\n",
        "                    # quasi-probability dict {bitstr: prob}. If observable given, we cannot easily evaluate here,\n",
        "                    # so try Z on lsb (qubit 0) expectation as fallback.\n",
        "                    if observable is None:\n",
        "                        total = 0.0\n",
        "                        totp = 0.0\n",
        "                        for bitstr, p in raw.items():\n",
        "                            try:\n",
        "                                b0 = int(bitstr[-1])\n",
        "                            except Exception:\n",
        "                                # if bitstr is int key\n",
        "                                b0 = int(bitstr) & 1\n",
        "                            total += ((-1) ** b0) * float(p)\n",
        "                            totp += float(p)\n",
        "                        if totp > 0:\n",
        "                            val = float(total / totp)\n",
        "                        else:\n",
        "                            val = 0.0\n",
        "                # last fallback: try to convert the raw object to float directly\n",
        "                if val is None:\n",
        "                    try:\n",
        "                        val = float(raw)\n",
        "                    except Exception:\n",
        "                        raise RuntimeError(\n",
        "                            \"Executor returned an unsupported result type; expected numeric or QuantumResult-like.\"\n",
        "                        )\n",
        "\n",
        "            vals_for_scale.append(float(val))\n",
        "\n",
        "        # average for this scale factor\n",
        "        avg_val = float(sum(vals_for_scale) / float(len(vals_for_scale)))\n",
        "        results.append(avg_val)\n",
        "\n",
        "    # Use the factory to produce the extrapolated estimate.\n",
        "    # Prefer factory.run(...) if available (it handles bookkeeping), otherwise emulate minimal contract:\n",
        "    try:\n",
        "        # if factory.run exists and returns a Factory-like run result, use that (safer for complex factories)\n",
        "        if hasattr(factory, \"run\"):\n",
        "            # many factory.run implementations expect: (circuit, executor, observable, scale_noise, num_to_average)\n",
        "            # but we already executed ourselves; some factories accept 'instack'/'outstack' directly: try to use reduce if possible.\n",
        "            # We'll attempt a minimal-compatible approach: set internal stacks and call reduce()\n",
        "            try:\n",
        "                # some Factory implementations expose instack/outstack attributes\n",
        "                if hasattr(factory, \"_instack\") and hasattr(factory, \"_outstack\"):\n",
        "                    # set instack/outstack using scale_factors and results\n",
        "                    factory._instack = [{\"scale_factor\": float(sf)} for sf in scale_factors]\n",
        "                    factory._outstack = list(results)\n",
        "                    est = float(factory.reduce())\n",
        "                    return est\n",
        "            except Exception:\n",
        "                # Fall through to call factory.run as a last resort (but factory.run expects an executor to run circuits)\n",
        "                pass\n",
        "\n",
        "        # If we get here, fallback to using the provided callable extrapolation if the factory exposes 'reduce' only\n",
        "        if hasattr(factory, \"reduce\"):\n",
        "            # set internal stacks if possible then reduce\n",
        "            if hasattr(factory, \"_instack\") and hasattr(factory, \"_outstack\"):\n",
        "                factory._instack = [{\"scale_factor\": float(sf)} for sf in scale_factors]\n",
        "                factory._outstack = list(results)\n",
        "                est = float(factory.reduce())\n",
        "                return est\n",
        "    except Exception:\n",
        "        # if factory internals are inaccessible, proceed to classical extrapolation fallback\n",
        "        pass\n",
        "\n",
        "    # Last-resort: try to use a small set of built-in extrapolators heuristically:\n",
        "    # for compatibility with the rest of your code, try to detect common factory types\n",
        "    # If factory is RichardsonFactory, perform simple Richardson extrapolation (polynomial fit with degree len-1)\n",
        "    try:\n",
        "        from mitiq.zne.inference import RichardsonFactory as _RF\n",
        "\n",
        "        if isinstance(factory, _RF):\n",
        "            # classical Richardson: fit polynomial in scale and evaluate at scale=0\n",
        "            coefs = np.polyfit(scale_factors, results, deg=min(len(scale_factors) - 1, 3))\n",
        "            # evaluate polynomial at 0 -> constant term is last coefficient in np.polyfit order\n",
        "            est = float(np.polyval(coefs, 0.0))\n",
        "            return est\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # If all else fails, use simple linear extrapolation (fit ax + b and return b)\n",
        "    coefs = np.polyfit(scale_factors, results, 1)\n",
        "    est = float(np.polyval(coefs, 0.0))\n",
        "    return est\n",
        "\n",
        "\n",
        "# --- mitigate_executor wrapper that returns a callable executor performing ZNE ---\n",
        "def mitigate_executor(\n",
        "    executor: Callable[[QPROGRAM], QuantumResult],\n",
        "    observable: Optional[Observable] = None,\n",
        "    *,\n",
        "    factory: Optional[Factory] = None,\n",
        "    scale_noise: Callable[[QPROGRAM, float], QPROGRAM] = fold_gates_at_random,  # type: ignore[has-type]\n",
        "    num_to_average: int = 1,\n",
        ") -> Callable[[QPROGRAM], float]:\n",
        "    \"\"\"\n",
        "    Wrap an executor function so that calling the returned function runs execute_with_zne.\n",
        "    If the input executor is batch-capable, the returned function will still perform per-circuit ZNE.\n",
        "    \"\"\"\n",
        "    # Best-effort wrap (support for mitiq.Executor instances or plain callables)\n",
        "    executor_obj = None\n",
        "    try:\n",
        "        # If user passed a Mitiq Executor instance, use as-is\n",
        "        if isinstance(executor, MitiqExecutor):\n",
        "            executor_obj = executor\n",
        "        else:\n",
        "            # otherwise wrap the callable in the mitiq.Executor helper if available\n",
        "            executor_obj = MitiqExecutor(executor) if hasattr(MitiqExecutor, \"__call__\") or True else executor\n",
        "    except Exception:\n",
        "        executor_obj = executor\n",
        "\n",
        "    # returned function handles both single circuit and list (if executor_obj supports batching it will be used internally)\n",
        "    def new_executor(circ_or_circuits):\n",
        "        # If the executor is a callable and input is list, we iterate calling execute_with_zne for each circuit.\n",
        "        if isinstance(circ_or_circuits, (list, tuple)):\n",
        "            outputs = []\n",
        "            for c in circ_or_circuits:\n",
        "                outputs.append(\n",
        "                    execute_with_zne(\n",
        "                        c,\n",
        "                        executor_obj,\n",
        "                        observable,\n",
        "                        factory=factory,\n",
        "                        scale_noise=scale_noise,\n",
        "                        num_to_average=num_to_average,\n",
        "                    )\n",
        "                )\n",
        "            return outputs\n",
        "        else:\n",
        "            return execute_with_zne(\n",
        "                circ_or_circuits,\n",
        "                executor_obj,\n",
        "                observable,\n",
        "                factory=factory,\n",
        "                scale_noise=scale_noise,\n",
        "                num_to_average=num_to_average,\n",
        "            )\n",
        "\n",
        "    return new_executor\n",
        "\n",
        "\n",
        "# --- zne_decorator: convenient decorator to wrap executors ---\n",
        "def zne_decorator(\n",
        "    observable: Optional[Observable] = None,\n",
        "    *,\n",
        "    factory: Optional[Factory] = None,\n",
        "    scale_noise: Callable[[QPROGRAM, float], QPROGRAM] = fold_gates_at_random,  # type: ignore[has-type]\n",
        "    num_to_average: int = 1,\n",
        ") -> Callable[[Callable[[QPROGRAM], QuantumResult]], Callable[[QPROGRAM], float]]:\n",
        "    \"\"\"\n",
        "    Return decorator which wraps an executor function to call ZNE when executed.\n",
        "    Usage:\n",
        "        @zne_decorator()\n",
        "        def my_executor(circuit):\n",
        "            ... return QuantumResult or float ...\n",
        "    \"\"\"\n",
        "    # If used without parentheses, disallow by checking callable observable\n",
        "    if callable(observable):\n",
        "        raise TypeError(\"zne_decorator must be used with parentheses, e.g. @zne_decorator()\")\n",
        "\n",
        "    def decorator(exec_fn: Callable[[QPROGRAM], QuantumResult]) -> Callable[[QPROGRAM], float]:\n",
        "        return mitigate_executor(exec_fn, observable, factory=factory, scale_noise=scale_noise, num_to_average=num_to_average)\n",
        "\n",
        "    return decorator\n"
      ],
      "metadata": {
        "id": "vPkZF-4HAVLE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RL environment using Mitiq for ZNE\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "\n",
        "# Import Mitiq and configure backends\n",
        "try:\n",
        "    import qiskit\n",
        "    from qiskit import QuantumCircuit\n",
        "    from qiskit.quantum_info import Statevector\n",
        "    HAS_QISKIT = True\n",
        "except Exception:\n",
        "    HAS_QISKIT = False\n",
        "    QuantumCircuit = None\n",
        "    Statevector = None\n",
        "\n",
        "try:\n",
        "    from mitiq import zne\n",
        "    from mitiq.zne.scaling import fold_gates_at_random\n",
        "    from mitiq.zne.inference import RichardsonFactory, PolyFactory\n",
        "    HAS_MITIQ = True\n",
        "except Exception:\n",
        "    HAS_MITIQ = False\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Data Classes\n",
        "# ----------------------------------------------------------\n",
        "@dataclass\n",
        "class HardwareProfile:\n",
        "    name: str\n",
        "    t1: float\n",
        "    two_q_time: float\n",
        "    base_error: float\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Mitiq-based ZNE Environment\n",
        "# ----------------------------------------------------------\n",
        "class ZNEEnvMitiq:\n",
        "    \"\"\"\n",
        "    RL Environment for Zero-Noise Extrapolation parameter selection using Mitiq.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        qc_or_desc,\n",
        "        hw: HardwareProfile,\n",
        "        pool: Optional[List[float]] = None,\n",
        "        max_folds: int = 4,\n",
        "        alpha: float = 0.1,\n",
        "        shots: int = 1024,\n",
        "    ):\n",
        "        self.qc = qc_or_desc\n",
        "        self.hw = hw\n",
        "        self.alpha = alpha\n",
        "        self.max_folds = max_folds\n",
        "        self.shots = shots\n",
        "\n",
        "        self.pool = pool or [1.0, 1.5, 2.0, 3.0]\n",
        "        self.E = 2  # 0: Richardson, 1: Polynomial (deg=2)\n",
        "        self.ACTIONS_PER_STEP = len(self.pool) + 1\n",
        "        self.done = False\n",
        "        self.selected = []\n",
        "        self.extrap_idx = None\n",
        "        self.ideal = 0.0\n",
        "        self.reset()\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # Observation generation\n",
        "    # ------------------------------------------------------\n",
        "    def _observation(self):\n",
        "        n = getattr(self.qc, \"num_qubits\", 4) if HAS_QISKIT else 4\n",
        "        depth = getattr(self.qc, \"depth\", lambda: 1)() if HAS_QISKIT else 1\n",
        "        return np.array(\n",
        "            [\n",
        "                float(n),\n",
        "                float(depth),\n",
        "                self.hw.t1,\n",
        "                self.hw.two_q_time,\n",
        "                self.hw.base_error,\n",
        "                len(self.selected),\n",
        "                sum(self.selected) if self.selected else 0.0,\n",
        "            ],\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # Reset\n",
        "    # ------------------------------------------------------\n",
        "    def reset(self):\n",
        "        self.done = False\n",
        "        self.selected = []\n",
        "        self.extrap_idx = None\n",
        "        self.ideal = self._compute_ideal()\n",
        "        return self._observation()\n",
        "\n",
        "    def _compute_ideal(self) -> float:\n",
        "        \"\"\"Compute ideal expectation .\"\"\"\n",
        "        if HAS_QISKIT and isinstance(self.qc, QuantumCircuit):\n",
        "            try:\n",
        "                sv = Statevector.from_instruction(self.qc)\n",
        "                probs = np.abs(sv.data) ** 2\n",
        "                expect = 0.0\n",
        "                for idx, p in enumerate(probs):\n",
        "                    bit0 = (idx >> 0) & 1\n",
        "                    expect += ((-1) ** bit0) * p\n",
        "                return float(expect)\n",
        "            except Exception:\n",
        "                pass\n",
        "        # Analytic fallback\n",
        "        return math.cos(0.2 * random.random())\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # Noise simulation\n",
        "    # ------------------------------------------------------\n",
        "    def _simulate_noisy(self, lam: float) -> float:\n",
        "        \"\"\"Analytic model: exponential decay in lam.\"\"\"\n",
        "        decay = self.hw.base_error * lam\n",
        "        noisy = self.ideal * math.exp(-decay) + np.random.normal(0, 0.02)\n",
        "        return max(-1.0, min(1.0, noisy))\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # Mitiq extrapolation run\n",
        "    # ------------------------------------------------------\n",
        "    def _run_zne(self, extrap_idx: int, lambdas: List[float]):\n",
        "        \"\"\"Use Mitiq factories for extrapolation.\"\"\"\n",
        "        vals = [self._simulate_noisy(l) for l in lambdas]\n",
        "        if not HAS_MITIQ:\n",
        "            est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
        "            return est, vals\n",
        "\n",
        "        # Choose factory\n",
        "        if extrap_idx == 0:\n",
        "            factory = RichardsonFactory(scale_factors=lambdas)\n",
        "        else:\n",
        "            factory = PolyFactory(scale_factors=lambdas, order=min(2, len(lambdas) - 1))\n",
        "\n",
        "        # Classical run using provided data\n",
        "        factory._instack = [{\"scale_factor\": l} for l in lambdas]\n",
        "        factory._outstack = vals\n",
        "        est = factory.reduce()\n",
        "        return est, vals\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # Step\n",
        "    # ------------------------------------------------------\n",
        "    def step(self, action: int):\n",
        "        if self.done:\n",
        "            raise RuntimeError(\"Episode already finished. Reset environment.\")\n",
        "        # Step 1: choose extrapolator\n",
        "        if self.extrap_idx is None:\n",
        "            if action not in [0, 1]:\n",
        "                raise ValueError(\"Invalid extrapolator choice\")\n",
        "            self.extrap_idx = int(action)\n",
        "            return self._observation(), 0.0, False, {}\n",
        "\n",
        "        # Step 2: choose lambda or stop\n",
        "        if action == self.ACTIONS_PER_STEP - 1:\n",
        "            # Stop and compute ZNE\n",
        "            lambdas = self.selected or [1.0]\n",
        "            est, vals = self._run_zne(self.extrap_idx, lambdas)\n",
        "            mse = (est - self.ideal) ** 2\n",
        "            cost = self.alpha * len(lambdas)\n",
        "            reward = -mse - cost\n",
        "            self.done = True\n",
        "            return (\n",
        "                self._observation(),\n",
        "                float(reward),\n",
        "                True,\n",
        "                {\"est\": est, \"ideal\": self.ideal, \"lambdas\": lambdas, \"vals\": vals},\n",
        "            )\n",
        "        else:\n",
        "            lam = float(self.pool[action])\n",
        "            if len(self.selected) < self.max_folds:\n",
        "                self.selected.append(lam)\n",
        "            return self._observation(), 0.0, False, {}\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Small test\n",
        "# ----------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    hw = HardwareProfile(name=\"sim\", t1=100.0, two_q_time=1.0, base_error=0.01)\n",
        "\n",
        "    if HAS_QISKIT:\n",
        "        qc = QuantumCircuit(2)\n",
        "        qc.h(0)\n",
        "        qc.cx(0, 1)\n",
        "    else:\n",
        "        qc = {\"n\": 4, \"steps\": 2}\n",
        "\n",
        "    env = ZNEEnvMitiq(qc, hw)\n",
        "    obs = env.reset()\n",
        "    print(\"Initial observation:\", obs)\n",
        "\n",
        "    # Choose Richardson extrapolation\n",
        "    obs, r, done, info = env.step(0)\n",
        "    # Choose two folds and stop\n",
        "    obs, r, done, info = env.step(1)\n",
        "    obs, r, done, info = env.step(2)\n",
        "    obs, r, done, info = env.step(env.ACTIONS_PER_STEP - 1)\n",
        "    print(\"Result:\", info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K4QYFmPvxKA",
        "outputId": "1324755b-ec2d-458d-e003-8b5c238f7a17"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial observation: [2.e+00 2.e+00 1.e+02 1.e+00 1.e-02 0.e+00 0.e+00]\n",
            "Result: {'est': np.float64(-0.05757762884358066), 'ideal': 0.0, 'lambdas': [1.5, 2.0], 'vals': [-0.031088819373481145, -0.022259216216781296]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PPO Agent (PyTorch) - hierarchical policy for extrapolator + fold sequence\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Actor-Critic Neural Network\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    \"\"\"\n",
        "    Shared actor-critic network for PPO.\n",
        "    - Shared feature extractor\n",
        "    - Separate heads for value and action logits\n",
        "    - Supports variable action dimensions via dynamic head creation\n",
        "    \"\"\"\n",
        "    def __init__(self, obs_dim, hidden=128):\n",
        "        super().__init__()\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(obs_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.value_head = nn.Linear(hidden, 1)\n",
        "        self.action_heads = {}  # dictionary: action_dim -> nn.Linear(hidden, action_dim)\n",
        "        self.hidden_dim = hidden\n",
        "\n",
        "    def forward_shared(self, obs: torch.Tensor):\n",
        "        return self.shared(obs)\n",
        "\n",
        "    def get_value(self, feat: torch.Tensor):\n",
        "        return self.value_head(feat).squeeze(-1)\n",
        "\n",
        "    def get_action_logits(self, feat: torch.Tensor, action_dim: int):\n",
        "        if action_dim not in self.action_heads:\n",
        "            # Lazy creation of head per unique action dimension\n",
        "            self.action_heads[action_dim] = nn.Linear(self.hidden_dim, action_dim).to(device)\n",
        "        logits = self.action_heads[action_dim](feat)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "# PPO Agent\n",
        "\n",
        "class PPOAgent:\n",
        "    def __init__(self, obs_dim, lr=3e-4, clip=0.2, epochs=4, gamma=0.99, lam=0.95):\n",
        "        self.net = ActorCritic(obs_dim).to(device)\n",
        "        self.optimizer = optim.Adam(self.net.parameters(), lr=lr)\n",
        "        self.clip = clip\n",
        "        self.epochs = epochs\n",
        "        self.gamma = gamma\n",
        "        self.lam = lam\n",
        "\n",
        "\n",
        "    # Select action using current policy\n",
        "    #\n",
        "    def select_action(self, obs_np, action_dim):\n",
        "        obs = torch.tensor(obs_np, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "        feat = self.net.forward_shared(obs)\n",
        "        logits = self.net.get_action_logits(feat, action_dim)\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        dist = Categorical(probs)\n",
        "        action = dist.sample()\n",
        "        logp = dist.log_prob(action)\n",
        "        entropy = dist.entropy()\n",
        "        return (\n",
        "            int(action.item()),\n",
        "            logp.detach(),\n",
        "            entropy.detach(),\n",
        "            probs.detach().cpu().numpy().ravel(),\n",
        "            feat.detach().cpu().numpy().ravel()\n",
        "        )\n",
        "\n",
        "\n",
        "    # Compute Generalized Advantage Estimate (GAE)\n",
        "    #\n",
        "    def compute_gae(self, rewards, masks, values):\n",
        "        # rewards: list, masks: list(0 if done else 1), values: list\n",
        "        values = values + [0.0]\n",
        "        gae = 0.0\n",
        "        returns = []\n",
        "        for step in reversed(range(len(rewards))):\n",
        "            delta = rewards[step] + self.gamma * values[step+1] * masks[step] - values[step]\n",
        "            gae = delta + self.gamma * self.lam * masks[step] * gae\n",
        "            returns.insert(0, gae + values[step])\n",
        "        return returns\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # PPO Update\n",
        "    # ------------------------------------------------------------\n",
        "    def update(self, trajectories):\n",
        "        \"\"\"\n",
        "        trajectories: list of dicts with keys\n",
        "        ['obs', 'action', 'logp', 'ret', 'value', 'action_dim']\n",
        "        \"\"\"\n",
        "\n",
        "        # Convert lists to detached tensors\n",
        "        obs = torch.tensor(np.vstack([t['obs'] for t in trajectories]), dtype=torch.float32, device=device)\n",
        "        actions = torch.tensor([t['action'] for t in trajectories], dtype=torch.long, device=device)\n",
        "        old_logps = torch.tensor([float(t['logp']) for t in trajectories], dtype=torch.float32, device=device).detach()\n",
        "        returns = torch.tensor([float(t['ret']) for t in trajectories], dtype=torch.float32, device=device).detach()\n",
        "        old_values = torch.tensor([float(t['value']) for t in trajectories], dtype=torch.float32, device=device).detach()\n",
        "\n",
        "        # Advantage (A = R - V)\n",
        "        advantages = (returns - old_values).detach()\n",
        "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
        "\n",
        "        # ------------------------------------------------------------\n",
        "        # Multiple PPO epochs (each uses a new forward pass)\n",
        "        # ------------------------------------------------------------\n",
        "        for _ in range(self.epochs):\n",
        "            feat = self.net.forward_shared(obs)  # fresh computation graph each epoch\n",
        "            action_dims = list(set([t['action_dim'] for t in trajectories]))\n",
        "\n",
        "            total_policy_loss = 0.0\n",
        "            total_value_loss = 0.0\n",
        "            group_count = 0\n",
        "\n",
        "            for ad in action_dims:\n",
        "                # indices for this action dimension\n",
        "                idxs = [i for i, t in enumerate(trajectories) if t['action_dim'] == ad]\n",
        "                if not idxs:\n",
        "                    continue\n",
        "                idxs_t = torch.tensor(idxs, dtype=torch.long, device=device)\n",
        "\n",
        "                feat_sub = feat[idxs_t]\n",
        "                logits = self.net.get_action_logits(feat_sub, ad)\n",
        "                dist = Categorical(logits=logits)\n",
        "                new_logp = dist.log_prob(actions[idxs_t])\n",
        "\n",
        "                ratio = torch.exp(new_logp - old_logps[idxs_t])\n",
        "                surr1 = ratio * advantages[idxs_t]\n",
        "                surr2 = torch.clamp(ratio, 1.0 - self.clip, 1.0 + self.clip) * advantages[idxs_t]\n",
        "                policy_loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "                value_pred = self.net.get_value(feat_sub)\n",
        "                value_loss = 0.5 * (returns[idxs_t] - value_pred).pow(2).mean()\n",
        "\n",
        "                total_policy_loss += policy_loss\n",
        "                total_value_loss += value_loss\n",
        "                group_count += 1\n",
        "\n",
        "            if group_count == 0:\n",
        "                continue\n",
        "\n",
        "            total_policy_loss /= float(group_count)\n",
        "            total_value_loss /= float(group_count)\n",
        "\n",
        "            loss = total_policy_loss + total_value_loss\n",
        "\n",
        "            # Backprop once per epoch\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return float(loss.item())\n"
      ],
      "metadata": {
        "id": "tcP6lUazdVlL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop tying environment and PPO agent\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "# - ---\n",
        "try:\n",
        "    tfim_trotter_circuit  # noqa: F821\n",
        "except NameError:\n",
        "    # create alias so legacy calls work\n",
        "    tfim_trotter_circuit = xyz_trotter_circuit\n",
        "\n",
        "# Training loop (PPO) - adapted to ZNEEnvMitiq\n",
        "def run_training(env_gen, episodes=200, max_steps=6, eval_every=50):\n",
        "    \"\"\"\n",
        "    env_gen: callable that returns a fresh env instance (ZNEEnvMitiq)\n",
        "    episodes: number of training episodes\n",
        "    max_steps: max fold-selection steps after extrapolator\n",
        "    eval_every: print progress every eval_every episodes\n",
        "    \"\"\"\n",
        "    # create sample env to get obs_dim\n",
        "    env0 = env_gen()\n",
        "    obs0 = env0.reset()\n",
        "    obs_dim = len(obs0)\n",
        "    agent = PPOAgent(obs_dim)   #\n",
        "    episode_rewards = []\n",
        "\n",
        "    for ep in range(1, episodes + 1):\n",
        "        env = env_gen()\n",
        "        obs = env.reset()\n",
        "        traj = []\n",
        "        values = []\n",
        "        masks = []\n",
        "        rewards_seq = []\n",
        "\n",
        "        # Stage 1: select extrapolator\n",
        "        action_dim = env.E\n",
        "        a, logp, ent, probs, feat = agent.select_action(obs, action_dim)\n",
        "        # compute value\n",
        "        value = float(agent.net.get_value(torch.tensor(feat, dtype=torch.float32, device=device).unsqueeze(0)).detach().cpu().numpy()[0])\n",
        "        traj.append({'obs': obs.copy(), 'action': a, 'logp': float(logp.detach().cpu().numpy()), 'value': value, 'action_dim': action_dim})\n",
        "        obs, r, done, info = env.step(a)\n",
        "        rewards_seq.append(0.0); masks.append(0 if done else 1); values.append(value)\n",
        "        if done:\n",
        "            # unlikely immediate done\n",
        "            ret = r\n",
        "            traj[-1]['ret'] = ret\n",
        "            agent.update(traj)\n",
        "            episode_rewards.append(ret)\n",
        "            continue\n",
        "\n",
        "        # Stage 2: sequential fold selection\n",
        "        for step in range(max_steps):\n",
        "            action_dim = env.ACTIONS_PER_STEP\n",
        "            a, logp, ent, probs, feat = agent.select_action(obs, action_dim)\n",
        "            value = float(agent.net.get_value(torch.tensor(feat, dtype=torch.float32, device=device).unsqueeze(0)).detach().cpu().numpy()[0])\n",
        "            obs_prev = obs.copy()\n",
        "            traj.append({'obs': obs_prev, 'action': a, 'logp': float(logp.detach().cpu().numpy()), 'value': value, 'action_dim': action_dim})\n",
        "            obs, r, done, info = env.step(a)\n",
        "            rewards_seq.append(float(r)); masks.append(0 if done else 1); values.append(value)\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # compute returns - simple Monte Carlo: set ret for each recorded step to final reward\n",
        "        final_reward = float(r if done else 0.0)\n",
        "        for t in traj:\n",
        "            t['ret'] = final_reward\n",
        "\n",
        "        # PPO update\n",
        "        agent.update(traj)\n",
        "        episode_rewards.append(final_reward)\n",
        "\n",
        "        if ep % eval_every == 0:\n",
        "            avg_last = np.mean(episode_rewards[-eval_every:])\n",
        "            print(f\"Ep {ep}/{episodes} avg_reward(last {eval_every})={avg_last:.4f}\")\n",
        "\n",
        "    return agent, episode_rewards\n",
        "\n",
        "\n",
        "#\n",
        "# S\n",
        "def env_generator_random():\n",
        "    # sample circuit params\n",
        "    if HAS_QISKIT:\n",
        "        n = random.randint(4, 8)\n",
        "        trotter = random.randint(1, 4)\n",
        "        # previously called tfim_trotter_circuit -> now alias exists\n",
        "        qc = xyz_trotter_circuit(n_qubits=n, trotter_steps=trotter, dt=0.05, with_measure=False)\n",
        "        circ_desc = qc\n",
        "    else:\n",
        "        n = random.randint(4, 8)\n",
        "        trotter = random.randint(1, 4)\n",
        "        circ_desc = {\"type\": \"xyz\", \"n\": n, \"steps\": trotter}\n",
        "\n",
        "    # hardware profile\n",
        "    hw = HardwareProfile(\n",
        "        name=\"sim\",\n",
        "        t1=random.uniform(50,200),\n",
        "        two_q_time=random.uniform(0.5,2.0),\n",
        "        base_error=random.uniform(0.002,0.02)\n",
        "    )\n",
        "    pool = [1.0, 1.2, 1.5, 2.0, 3.0]\n",
        "    return ZNEEnvMitiq(circ_desc, hw, pool=pool, max_folds=3, alpha=0.05, shots=1024)\n",
        "\n",
        "\n",
        "\n",
        "agent, rewards = run_training(env_generator_random, episodes=60, max_steps=3, eval_every=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "UTwST7kLAP0M",
        "outputId": "111bdbc3-5633-4a8b-fa16-56352d62f231"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'HardwareProfile' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2501716630.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_generator_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2501716630.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(env_gen, episodes, max_steps, eval_every)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# create sample env to get obs_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0menv0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mobs0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mobs_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2501716630.py\u001b[0m in \u001b[0;36menv_generator_random\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# hardware profile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     hw = HardwareProfile(\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sim\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'HardwareProfile' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of trained PPO agent on ZNE environment\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_agent(agent, env_gen, episodes: int = 10, verbose: bool = True):\n",
        "    \"\"\"\n",
        "    Evaluate a trained PPO agent over multiple ZNE environment runs.\n",
        "\n",
        "    Args:\n",
        "        agent: Trained PPOAgent.\n",
        "        env_gen: Callable that creates a fresh ZNEEnvMitiq instance.\n",
        "        episodes: Number of evaluation episodes.\n",
        "        verbose: If True, print summary statistics per episode.\n",
        "\n",
        "    Returns:\n",
        "        stats: List of dictionaries with keys:\n",
        "            [\"ideal\", \"est\", \"lambdas\", \"vals\", \"reward\", \"error\"]\n",
        "    \"\"\"\n",
        "    stats = []\n",
        "\n",
        "    for ep in range(episodes):\n",
        "        env = env_gen()\n",
        "        obs = env.reset()\n",
        "\n",
        "        # --- Stage 1: Select extrapolator type (e.g., Richardson or Polynomial)\n",
        "        a, logp, ent, probs, feat = agent.select_action(obs, env.E)\n",
        "        obs, r, done, info = env.step(a)\n",
        "\n",
        "        # --- Stage 2: Sequentially select lambdas or stop ---\n",
        "        for _ in range(env.max_folds + 1):\n",
        "            a, logp, ent, probs, feat = agent.select_action(obs, env.ACTIONS_PER_STEP)\n",
        "            obs, r, done, info = env.step(a)\n",
        "            if done:\n",
        "                break\n",
        "        else:\n",
        "            # If not stopped by done flag, force STOP\n",
        "            obs, r, done, info = env.step(env.ACTIONS_PER_STEP - 1)\n",
        "\n",
        "        # --- Collect episode info ---\n",
        "        record = {\n",
        "            \"ideal\": info.get(\"ideal\", 0.0),\n",
        "            \"est\": info.get(\"est\", 0.0),\n",
        "            \"lambdas\": info.get(\"lambdas\", []),\n",
        "            \"vals\": info.get(\"vals\", []),\n",
        "            \"reward\": r,\n",
        "        }\n",
        "        record[\"error\"] = abs(record[\"est\"] - record[\"ideal\"])\n",
        "        stats.append(record)\n",
        "\n",
        "        if verbose:\n",
        "            print(\n",
        "                f\"[Ep {ep+1:02d}] ideal={record['ideal']:.4f}, \"\n",
        "                f\"est={record['est']:.4f}, \"\n",
        "                f\"error={record['error']:.4f}, \"\n",
        "                f\"reward={record['reward']:.4f}, \"\n",
        "                f\"lambdas={record['lambdas']}, \"\n",
        "                f\"vals={np.round(record['vals'], 3)}\"\n",
        "            )\n",
        "\n",
        "    return stats\n"
      ],
      "metadata": {
        "id": "hvqpcJYU723m"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training:\n",
        "stats = evaluate_agent(agent, env_generator_random, episodes=5)\n",
        "\n",
        "# Compute summary statistics\n",
        "mean_error = np.mean([s[\"error\"] for s in stats])\n",
        "print(f\"\\nAverage |est - ideal| error = {mean_error:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQtjCMSv8Rd-",
        "outputId": "c9bd1f34-2f70-47f3-c698-211ea56be907"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 01] ideal=1.0000, est=0.4736, error=0.5263, reward=-0.4270, lambdas=[3.0, 3.0, 3.0], vals=[0.931 0.947 0.964]\n",
            "[Ep 02] ideal=1.0000, est=0.4723, error=0.5277, reward=-0.4284, lambdas=[3.0, 3.0, 3.0], vals=[0.951 0.963 0.92 ]\n",
            "[Ep 03] ideal=0.9807, est=0.4801, error=0.5006, reward=-0.4006, lambdas=[3.0, 3.0, 3.0], vals=[0.965 0.931 0.984]\n",
            "[Ep 04] ideal=0.9957, est=0.4924, error=0.5034, reward=-0.4034, lambdas=[3.0, 3.0, 3.0], vals=[0.999 0.992 0.964]\n",
            "[Ep 05] ideal=0.9868, est=0.4739, error=0.5129, reward=-0.4131, lambdas=[3.0, 3.0, 3.0], vals=[0.914 0.948 0.981]\n",
            "\n",
            "Average |est - ideal| error = 0.5142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#\n",
        "#  Evaluation & diagnostics for ZNE-RL training\n",
        "def evaluate_agent(agent, env_gen, episodes=20, render=False):\n",
        "    \"\"\"\n",
        "    Evaluate the trained RL agent on unseen circuits.\n",
        "    Returns per-episode info dicts.\n",
        "    \"\"\"\n",
        "    stats = []\n",
        "    for ep in range(episodes):\n",
        "        env = env_gen()\n",
        "        obs = env.reset()\n",
        "\n",
        "        # --- Stage 1: choose extrapolator (0=Richardson, 1=Poly)\n",
        "        a, logp, ent, probs, feat = agent.select_action(obs, env.E)\n",
        "        obs, r, done, info = env.step(a)\n",
        "\n",
        "        # --- Stage 2: sequential fold selection until STOP\n",
        "        for _ in range(env.max_folds + 1):\n",
        "            a, logp, ent, probs, feat = agent.select_action(obs, env.ACTIONS_PER_STEP)\n",
        "            obs, r, done, info = env.step(a)\n",
        "            if done:\n",
        "                stats.append({\n",
        "                    \"ideal\": info.get(\"ideal\", 0.0),\n",
        "                    \"est\": info.get(\"est\", 0.0),\n",
        "                    \"lambdas\": info.get(\"lambdas\", []),\n",
        "                    \"vals\": info.get(\"vals\", []),\n",
        "                    \"reward\": r\n",
        "                })\n",
        "                break\n",
        "        else:\n",
        "            # If agent never stopped, force stop and record\n",
        "            obs, r, done, info = env.step(env.ACTIONS_PER_STEP - 1)\n",
        "            stats.append({\n",
        "                \"ideal\": info.get(\"ideal\", 0.0),\n",
        "                \"est\": info.get(\"est\", 0.0),\n",
        "                \"lambdas\": info.get(\"lambdas\", []),\n",
        "                \"vals\": info.get(\"vals\", []),\n",
        "                \"reward\": r\n",
        "            })\n",
        "    return stats\n",
        "\n",
        "\n",
        "def evaluate_random_policy(env_gen, episodes=20):\n",
        "    \"\"\"Random baseline (no RL).\"\"\"\n",
        "    stats = []\n",
        "    for ep in range(episodes):\n",
        "        env = env_gen()\n",
        "        obs = env.reset()\n",
        "        extrap = np.random.choice([0, 1])\n",
        "        obs, r, done, info = env.step(extrap)\n",
        "        for _ in range(env.max_folds + 1):\n",
        "            action = np.random.choice(env.ACTIONS_PER_STEP)\n",
        "            obs, r, done, info = env.step(action)\n",
        "            if done:\n",
        "                stats.append({\n",
        "                    \"ideal\": info.get(\"ideal\", 0.0),\n",
        "                    \"est\": info.get(\"est\", 0.0),\n",
        "                    \"lambdas\": info.get(\"lambdas\", []),\n",
        "                    \"vals\": info.get(\"vals\", []),\n",
        "                    \"reward\": r\n",
        "                })\n",
        "                break\n",
        "    return stats\n",
        "\n",
        "\n",
        "def evaluate_fixed_policy(env_gen, episodes=20):\n",
        "    \"\"\"Fixed heuristic baseline: Richardson extrapolation with fixed lambdas [1,2,3].\"\"\"\n",
        "    stats = []\n",
        "    for ep in range(episodes):\n",
        "        env = env_gen()\n",
        "        obs = env.reset()\n",
        "        # Richardson\n",
        "        obs, r, done, info = env.step(0)\n",
        "        # Fixed folds: [1.0, 2.0, 3.0]\n",
        "        for lam in [0, 2, 3]:  # indices in pool = [1.0, 1.2, 1.5, 2.0, 3.0]\n",
        "            obs, r, done, info = env.step(lam)\n",
        "        obs, r, done, info = env.step(env.ACTIONS_PER_STEP - 1)  # stop\n",
        "        stats.append({\n",
        "            \"ideal\": info.get(\"ideal\", 0.0),\n",
        "            \"est\": info.get(\"est\", 0.0),\n",
        "            \"lambdas\": info.get(\"lambdas\", []),\n",
        "            \"vals\": info.get(\"vals\", []),\n",
        "            \"reward\": r\n",
        "        })\n",
        "    return stats\n",
        "\n",
        "\n",
        "def summarize_results(name, stats):\n",
        "    ideals = np.array([s[\"ideal\"] for s in stats])\n",
        "    ests = np.array([s[\"est\"] for s in stats])\n",
        "    rewards = np.array([s[\"reward\"] for s in stats])\n",
        "    mse = np.mean((ideals - ests)**2)\n",
        "    mae = np.mean(np.abs(ideals - ests))\n",
        "    avg_reward = np.mean(rewards)\n",
        "    print(f\"{name:>12s} | MSE={mse:.4e} | MAE={mae:.4e} | AvgReward={avg_reward:+.4f}\")\n",
        "    return mse, mae, avg_reward\n"
      ],
      "metadata": {
        "id": "qqS4AV1nIFHW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rl_stats = evaluate_agent(agent, env_generator_random, episodes=30)\n",
        "rnd_stats = evaluate_random_policy(env_generator_random, episodes=30)\n",
        "fix_stats = evaluate_fixed_policy(env_generator_random, episodes=30)\n",
        "\n",
        "print(\"=== Evaluation Results ===\")\n",
        "summarize_results(\"RL Agent\", rl_stats)\n",
        "summarize_results(\"Random\", rnd_stats)\n",
        "summarize_results(\"Fixed\", fix_stats)\n",
        "\n",
        "# Optional: inspect a few detailed cases\n",
        "for i, s in enumerate(rl_stats[:5]):\n",
        "    print(f\"[Ep {i}] ideal={s['ideal']:.3f}, est={s['est']:.3f}, reward={s['reward']:.3f}, lambdas={s['lambdas']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nysqLt9TIGpO",
        "outputId": "2f194dc8-3ce6-4bb8-fc0d-0daefb5b2663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-1776838787.py:134: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluation Results ===\n",
            "    RL Agent | MSE=1.0286e-01 | MAE=2.2041e-01 | AvgReward=-0.2529\n",
            "      Random | MSE=1.8424e-01 | MAE=3.7230e-01 | AvgReward=-0.2592\n",
            "       Fixed | MSE=1.4833e-03 | MAE=3.1193e-02 | AvgReward=-0.1515\n",
            "[Ep 0] ideal=0.982, est=0.954, reward=-0.151, lambdas=[1.0, 2.0, 1.0]\n",
            "[Ep 1] ideal=0.990, est=0.488, reward=-0.401, lambdas=[1.0, 1.0, 1.0]\n",
            "[Ep 2] ideal=0.992, est=0.478, reward=-0.414, lambdas=[1.0, 1.0, 1.0]\n",
            "[Ep 3] ideal=0.991, est=0.493, reward=-0.398, lambdas=[1.0, 1.0, 1.0]\n",
            "[Ep 4] ideal=0.992, est=0.481, reward=-0.412, lambdas=[1.0, 1.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Evaluation of trained PPO agent for ZNE parameter selection\n",
        "#\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def evaluate_agent(agent, env_gen, episodes=20, compare_random=True):\n",
        "    \"\"\"\n",
        "    Evaluate PPO agent vs random baseline on ZNE environment.\n",
        "\n",
        "    Returns:\n",
        "        stats_agent: list of dicts from env info for trained agent\n",
        "        stats_random: same, for random actions\n",
        "    \"\"\"\n",
        "    def run_policy(policy_fn, episodes):\n",
        "        stats = []\n",
        "        for ep in range(episodes):\n",
        "            env = env_gen()\n",
        "            obs = env.reset()\n",
        "\n",
        "            # Stage 1: choose extrapolator (0=Richardson, 1=Poly)\n",
        "            a, *_ = policy_fn(obs, env.E)\n",
        "            obs, _, done, info = env.step(a)\n",
        "\n",
        "            # Stage 2: choose lambda folds\n",
        "            for _ in range(env.max_folds + 1):\n",
        "                a, *_ = policy_fn(obs, env.ACTIONS_PER_STEP)\n",
        "                obs, r, done, info = env.step(a)\n",
        "                if done:\n",
        "                    stats.append(info)\n",
        "                    break\n",
        "            else:\n",
        "                # Force stop if max steps reached\n",
        "                obs, r, done, info = env.step(env.ACTIONS_PER_STEP - 1)\n",
        "                stats.append(info)\n",
        "        return stats\n",
        "\n",
        "    # --- Run agent policy ---\n",
        "    def agent_policy(obs, action_dim):\n",
        "        a, logp, ent, probs, feat = agent.select_action(obs, action_dim)\n",
        "        return a, logp, ent, probs, feat\n",
        "\n",
        "    stats_agent = run_policy(agent_policy, episodes)\n",
        "\n",
        "    # --- Optional random baseline ---\n",
        "    stats_random = []\n",
        "    if compare_random:\n",
        "        def random_policy(obs, action_dim):\n",
        "            a = np.random.randint(0, action_dim)\n",
        "            return a, None, None, None, None\n",
        "        stats_random = run_policy(random_policy, episodes)\n",
        "\n",
        "    # --- Compute summary metrics ---\n",
        "    def summarize(stats, label=\"Agent\"):\n",
        "        if not stats:\n",
        "            return {}\n",
        "        ideals = np.array([s[\"ideal\"] for s in stats])\n",
        "        ests = np.array([s[\"est\"] for s in stats])\n",
        "        errors = (ests - ideals) ** 2\n",
        "        mean_err = np.mean(errors)\n",
        "        mean_abs = np.mean(np.abs(ests - ideals))\n",
        "        mean_lams = np.mean([len(s[\"lambdas\"]) for s in stats])\n",
        "        print(f\"{label}: MSE={mean_err:.5f}, MAE={mean_abs:.5f}, Avg λ count={mean_lams:.2f}\")\n",
        "        return {\"mse\": mean_err, \"mae\": mean_abs, \"lams\": mean_lams}\n",
        "\n",
        "    print(\"=== Evaluation Results ===\")\n",
        "    res_agent = summarize(stats_agent, \"Trained Agent\")\n",
        "    if compare_random:\n",
        "        res_random = summarize(stats_random, \"Random Policy\")\n",
        "\n",
        "        # Relative improvement\n",
        "        if res_random and res_agent:\n",
        "            imp = 100 * (1 - res_agent[\"mse\"] / (res_random[\"mse\"] + 1e-12))\n",
        "            print(f\"Relative improvement in MSE vs random: {imp:.1f}%\")\n",
        "\n",
        "    # --- t ---\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.scatter(\n",
        "        [s[\"ideal\"] for s in stats_agent],\n",
        "        [s[\"est\"] for s in stats_agent],\n",
        "        label=\"Agent\", color=\"tab:blue\", marker=\"o\"\n",
        "    )\n",
        "    if compare_random:\n",
        "        plt.scatter(\n",
        "            [s[\"ideal\"] for s in stats_random],\n",
        "            [s[\"est\"] for s in stats_random],\n",
        "            label=\"Random\", color=\"tab:red\", marker=\"x\"\n",
        "        )\n",
        "    plt.plot([-1, 1], [-1, 1], \"k--\", alpha=0.5)\n",
        "    plt.xlabel(\"Ideal value\")\n",
        "    plt.ylabel(\"Extrapolated estimate\")\n",
        "    plt.title(\"ZNE Extrapolation Quality\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- Print example episodes ---\n",
        "    print(\"\\nSample episodes:\")\n",
        "    for s in stats_agent[:5]:\n",
        "        print(f\"ideal={s['ideal']:.4f}, est={s['est']:.4f}, λs={s['lambdas']}, vals={np.round(s['vals'],3)}\")\n",
        "\n",
        "    return stats_agent, stats_random\n",
        "\n",
        "\n",
        "# Example evaluation after training\n",
        "stats_agent, stats_random = evaluate_agent(agent, env_generator_random, episodes=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "37wcYogLIOmd",
        "outputId": "ac5bd976-11b8-43eb-f021-c133dee3484a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n",
            "/tmp/ipython-input-652736040.py:131: RankWarning: Polyfit may be poorly conditioned\n",
            "  est = np.polyfit(lambdas, vals, 1)[1]  # fallback linear\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluation Results ===\n",
            "Trained Agent: MSE=0.25932, MAE=0.50918, Avg λ count=3.00\n",
            "Random Policy: MSE=0.10674, MAE=0.24585, Avg λ count=2.20\n",
            "Relative improvement in MSE vs random: -143.0%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample episodes:\n",
            "ideal=0.9891, est=0.4802, λs=[3.0, 3.0, 3.0], vals=[0.956 0.937 0.987]\n",
            "ideal=0.9969, est=0.4940, λs=[3.0, 3.0, 3.0], vals=[1.    0.988 0.976]\n",
            "ideal=0.9933, est=0.4854, λs=[3.0, 3.0, 3.0], vals=[1.    0.981 0.932]\n",
            "ideal=1.0000, est=0.4738, λs=[3.0, 3.0, 3.0], vals=[0.968 0.94  0.935]\n",
            "ideal=0.9883, est=0.4854, λs=[3.0, 3.0, 3.0], vals=[0.951 0.991 0.97 ]\n"
          ]
        }
      ]
    }
  ]
}